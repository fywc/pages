[
  {
    "objectID": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html",
    "href": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html",
    "title": "Deadlock-Livelock-Starvation",
    "section": "",
    "text": "In a multiprogramming environment, more than one process may compete for a finite set of resources. If a process requests for a resource and the resource is not presently available, then the process waits for it. Sometimes this waiting process never succeeds to get access to the resource. This waiting for resources leads to three scenarios – deadlock, livelock, and starvation.\n\n\n\nIn this section, we’ll first discuss deadlock, its necessary conditions, and how to prevent it.\n\n\nA deadlock is a situation in which processes block each other due to resource acquisition and none of the processes makes any progress as they wait for the resource held by the other process.\n\nThe above figure shows the deadlock scenario between process 1 and process 2. Both processes are holding one resource and waiting for the other resource held by the other process. This is a deadlock situation as neither process 1 or process 2 can make progress until one of the processes gives up its resource.\n\n\n\nTo successfully characterize a scenario as deadlock, the following four conditions must hold simultaneously:\nMutual Exclusion: At least one resource needs to be held by a process in a non-sharable mode. Any other process requesting that resource needs to wait.\nHold and Wait: A process must hold one resource and requests additional resources that are currently held by other processes.\nNo Preemption: A resource can’t be forcefully released from a process. A process can only release a resource voluntarily once it deems to release.\nCircular Wait: A set of a process p0,p1,p2,…pn exists in a manner that p0 is waiting for a resource held by p1, pn-1 waiting for a resource held by p0.\n\n\n\nTo prevent the occurrence of deadlock, at least one of the necessary conditions discussed in the previous section should not hold true. Let us examine the possibility of any of these conditions being false:\nMutual Exclusion: In some cases, this condition can be false. For example, in a read-only file system, one or more processes can be granted sharable access. However, this condition can’t always be false. The reason being some resources are intrinsically non-sharable. For instance, a mutex lock is a non-sharable resource.\nHold and Wait: To ensure that the hold-and-wait condition never occurs, we need to guarantee that once a process requests for a resource it is not holding any other resource at that time. In general, a process should request all resources before it begins its execution.\nNo Preemption: To make this condition false, a process needs to make sure that it automatically releases all currently held resources if the newly requested resource is not available.\nCircular Wait: This condition can be made false by imposing a total ordering of all resource types and ensure that each process requests resources in increasing order of enumeration.\n\n\n\n\nIn this section, we’ll discuss live lock which is similar to deadlock with a subtle difference.\n\n\nIn the case of a livelock, the states of the processes involved in a live lock scenario constantly change. On the other hand, the processes still depend on each other and can never finish their tasks.\n\nThe above figure shows an example of livelock. Both “process 1” and “process 2” need a common resource. Each process checks whether the other process is in an active state. If so, then it hands over the resource to the other process. However as both, the process is inactive status, both kept on handing over the resource to each other indefinitely.\nA real-world example of livelock occurs when two people make a telephone call to each other and both find the line is busy. Both gentlemen decide to hang up and attempt to call after the same time interval. Thus, in the next retry too, they ended up in the same situation. This is an example of a live lock as this can go on forever.\n\n\n\nAlthough similar in nature, deadlock, and live locks are not the same. In a deadlock, processes involved in a deadlock are stuck indefinitely and do not make any state change. However, in a live lock scenario, processes block each other and wait indefinitely but they change their resource state continuously. The notable point is that the resource state change has no effect and does not help the processes make any progress in their task.\n\n\n\n\nIn this section, we’ll discuss starvation which generally occurs as a result of a deadlock, livelock, or caused by a greedy process.\n\n\nStarvation is an outcome of a process that is unable to gain regular access to the shared resources it requires to complete a task and thus, unable to make any progress.\n\nThe above figure shows an example of starvation of “process 2” and “process 3” for the CPU as “process 1” is occupying it for a long duration.\n\n\n\nStarvation can occur due to deadlock, livelock, or caused by another process.\nAs we have seen in the event of a deadlock or a live lock a process competes with another process to acquire the desired resource to complete its task. However, due to the deadlock or livelock scenario, it failed to acquire the resource and generally starved for the resource.\nFurther, it may occur that a process repeatedly gains access to a shared resource or use it for a longer duration while other processes wait for the same resource. Thus, the waiting processes are starved for the resource by the greedy process.\n\n\n\nOne of the possible solutions to prevent starvation is to use a resource scheduling algorithm with a priority queue that also uses the aging technique. Aging is a technique that periodically increases the priority of a waiting process. With this approach, any process waiting for a resource for a longer duration eventually gains a higher priority. And as the resource sharing is driven through the priority of the process, no process starves for a resource indefinitely.\nAnother solution to prevent starvation is to follow the round-robin pattern while allocating the resources to a process. In this pattern, the resource is fairly allocated to each process providing a chance to use the resource before it is allocated to another process again.\n\n\n\n\nIn this article, we discussed concepts of deadlock, livelock, and starvation which occur in a multi-processing operating system.\nA deadlock is a situation that occurs when processes block each other with resource acquisition and makes no further progress. Livelock is a deadlock-like situation in which processes block each other with a repeated state change yet make no progress. Starvation is the outcome of a deadlock, livelock, or as a result of continuous resource denial to a process."
  },
  {
    "objectID": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#introduction",
    "href": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#introduction",
    "title": "Deadlock-Livelock-Starvation",
    "section": "",
    "text": "In a multiprogramming environment, more than one process may compete for a finite set of resources. If a process requests for a resource and the resource is not presently available, then the process waits for it. Sometimes this waiting process never succeeds to get access to the resource. This waiting for resources leads to three scenarios – deadlock, livelock, and starvation."
  },
  {
    "objectID": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#deadlock",
    "href": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#deadlock",
    "title": "Deadlock-Livelock-Starvation",
    "section": "",
    "text": "In this section, we’ll first discuss deadlock, its necessary conditions, and how to prevent it.\n\n\nA deadlock is a situation in which processes block each other due to resource acquisition and none of the processes makes any progress as they wait for the resource held by the other process.\n\nThe above figure shows the deadlock scenario between process 1 and process 2. Both processes are holding one resource and waiting for the other resource held by the other process. This is a deadlock situation as neither process 1 or process 2 can make progress until one of the processes gives up its resource.\n\n\n\nTo successfully characterize a scenario as deadlock, the following four conditions must hold simultaneously:\nMutual Exclusion: At least one resource needs to be held by a process in a non-sharable mode. Any other process requesting that resource needs to wait.\nHold and Wait: A process must hold one resource and requests additional resources that are currently held by other processes.\nNo Preemption: A resource can’t be forcefully released from a process. A process can only release a resource voluntarily once it deems to release.\nCircular Wait: A set of a process p0,p1,p2,…pn exists in a manner that p0 is waiting for a resource held by p1, pn-1 waiting for a resource held by p0.\n\n\n\nTo prevent the occurrence of deadlock, at least one of the necessary conditions discussed in the previous section should not hold true. Let us examine the possibility of any of these conditions being false:\nMutual Exclusion: In some cases, this condition can be false. For example, in a read-only file system, one or more processes can be granted sharable access. However, this condition can’t always be false. The reason being some resources are intrinsically non-sharable. For instance, a mutex lock is a non-sharable resource.\nHold and Wait: To ensure that the hold-and-wait condition never occurs, we need to guarantee that once a process requests for a resource it is not holding any other resource at that time. In general, a process should request all resources before it begins its execution.\nNo Preemption: To make this condition false, a process needs to make sure that it automatically releases all currently held resources if the newly requested resource is not available.\nCircular Wait: This condition can be made false by imposing a total ordering of all resource types and ensure that each process requests resources in increasing order of enumeration."
  },
  {
    "objectID": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#livelock",
    "href": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#livelock",
    "title": "Deadlock-Livelock-Starvation",
    "section": "",
    "text": "In this section, we’ll discuss live lock which is similar to deadlock with a subtle difference.\n\n\nIn the case of a livelock, the states of the processes involved in a live lock scenario constantly change. On the other hand, the processes still depend on each other and can never finish their tasks.\n\nThe above figure shows an example of livelock. Both “process 1” and “process 2” need a common resource. Each process checks whether the other process is in an active state. If so, then it hands over the resource to the other process. However as both, the process is inactive status, both kept on handing over the resource to each other indefinitely.\nA real-world example of livelock occurs when two people make a telephone call to each other and both find the line is busy. Both gentlemen decide to hang up and attempt to call after the same time interval. Thus, in the next retry too, they ended up in the same situation. This is an example of a live lock as this can go on forever.\n\n\n\nAlthough similar in nature, deadlock, and live locks are not the same. In a deadlock, processes involved in a deadlock are stuck indefinitely and do not make any state change. However, in a live lock scenario, processes block each other and wait indefinitely but they change their resource state continuously. The notable point is that the resource state change has no effect and does not help the processes make any progress in their task."
  },
  {
    "objectID": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#starvation",
    "href": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#starvation",
    "title": "Deadlock-Livelock-Starvation",
    "section": "",
    "text": "In this section, we’ll discuss starvation which generally occurs as a result of a deadlock, livelock, or caused by a greedy process.\n\n\nStarvation is an outcome of a process that is unable to gain regular access to the shared resources it requires to complete a task and thus, unable to make any progress.\n\nThe above figure shows an example of starvation of “process 2” and “process 3” for the CPU as “process 1” is occupying it for a long duration.\n\n\n\nStarvation can occur due to deadlock, livelock, or caused by another process.\nAs we have seen in the event of a deadlock or a live lock a process competes with another process to acquire the desired resource to complete its task. However, due to the deadlock or livelock scenario, it failed to acquire the resource and generally starved for the resource.\nFurther, it may occur that a process repeatedly gains access to a shared resource or use it for a longer duration while other processes wait for the same resource. Thus, the waiting processes are starved for the resource by the greedy process.\n\n\n\nOne of the possible solutions to prevent starvation is to use a resource scheduling algorithm with a priority queue that also uses the aging technique. Aging is a technique that periodically increases the priority of a waiting process. With this approach, any process waiting for a resource for a longer duration eventually gains a higher priority. And as the resource sharing is driven through the priority of the process, no process starves for a resource indefinitely.\nAnother solution to prevent starvation is to follow the round-robin pattern while allocating the resources to a process. In this pattern, the resource is fairly allocated to each process providing a chance to use the resource before it is allocated to another process again."
  },
  {
    "objectID": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#conclusion",
    "href": "posts/死锁活锁饥饿/Deadlock-Livelock-Starvation.html#conclusion",
    "title": "Deadlock-Livelock-Starvation",
    "section": "",
    "text": "In this article, we discussed concepts of deadlock, livelock, and starvation which occur in a multi-processing operating system.\nA deadlock is a situation that occurs when processes block each other with resource acquisition and makes no further progress. Livelock is a deadlock-like situation in which processes block each other with a repeated state change yet make no progress. Starvation is the outcome of a deadlock, livelock, or as a result of continuous resource denial to a process."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html",
    "title": "Linux 内核设备和模块",
    "section": "",
    "text": "设备类型\n\n伪设备\n杂项设备\n模块\n构建模块\n\n放在内核源码树中\n放在内核源码树外\n\n安装模块\n模块依赖性\n载入模块\n模块参数\n导出符号表\n设备模型\n\nkobject\nktype\nkset\n\n引用计数\n\nsysfs\n\nsysfs中添加和删除kobject\n向sysfs中添加文件(attr)\n默认文件\n文件的创建与修改\nsysfs约定　\n内核事件层\n\nNext Section"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#目录",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#目录",
    "title": "Linux 内核设备和模块",
    "section": "",
    "text": "设备类型\n\n伪设备\n杂项设备\n模块\n构建模块\n\n放在内核源码树中\n放在内核源码树外\n\n安装模块\n模块依赖性\n载入模块\n模块参数\n导出符号表\n设备模型\n\nkobject\nktype\nkset\n\n引用计数\n\nsysfs\n\nsysfs中添加和删除kobject\n向sysfs中添加文件(attr)\n默认文件\n文件的创建与修改\nsysfs约定　\n内核事件层\n\nNext Section"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#伪设备",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#伪设备",
    "title": "Linux 内核设备和模块",
    "section": "伪设备",
    "text": "伪设备\n一些虚拟设备驱动，仅提供访问内核功能．\n\n内核随机数发生器\n空设备 /dev/null\n零设备 /dev/zero\n满设备 /dev/full\n内存设备 /dev/mem"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#杂项设备",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#杂项设备",
    "title": "Linux 内核设备和模块",
    "section": "杂项设备",
    "text": "杂项设备\n简写为miscdev，是对字符设备的封装，方便使用．"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#模块",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#模块",
    "title": "Linux 内核设备和模块",
    "section": "模块",
    "text": "模块\n内核在运行时动态向其中插入或删除代码，这些代码以模块的形式组合在一个单独的二进制镜像．"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#构建模块",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#构建模块",
    "title": "Linux 内核设备和模块",
    "section": "构建模块",
    "text": "构建模块\n\n放在内核源码树中\n\n字符设备存放在drivers/char/\n块设备存放在drivers/block \nUSE设备存放在 drivers/usb/ \n\n添加一个字符设备fishing , 编辑drivers/char/Makefile 并加入obj-m += fishing/\n在drivers/char/fishing/下,需要添加一个新的Makefile文件：\nobj-m += fishing.o\nfishing-objs := fishing-main.o fishing-line.o\n这样编译内核时，也会自动编译该模块，最终编译链接完的文件名为fishing.ko \n\n\n放在内核源码树外\n假设放在/home/dev/fishing/目录中，那么修改/home/dev/fishing/Makefile :\nobj-m += fishing.o\nfishing-objs := fishing-main.o fishing-line.o\n编译时需要在/home/dev/fishing/目录下，然后执行:\nmake -C /mnt/disk/kernelsrc/ SUBDIRS=$PWD modules\n其中/mnt/disk/kernelsrc/就是内核源码目录"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#安装模块",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#安装模块",
    "title": "Linux 内核设备和模块",
    "section": "安装模块",
    "text": "安装模块\n使用make modules_install"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#模块依赖性",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#模块依赖性",
    "title": "Linux 内核设备和模块",
    "section": "模块依赖性",
    "text": "模块依赖性\nLinux模块之间存在依赖性，依赖关系存放在/libmodules/}version}/modules.dep 文件．\n使用depmod 命令产生依赖信息，-A 参数表示仅更新新模块的依赖信息."
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#载入模块",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#载入模块",
    "title": "Linux 内核设备和模块",
    "section": "载入模块",
    "text": "载入模块\ninsmod fishing.ko\nrmmod fishing.ko\nmodprobe modules\nmodprobe -r modules"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#模块参数",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#模块参数",
    "title": "Linux 内核设备和模块",
    "section": "模块参数",
    "text": "模块参数\nLinux 允许驱动程序声明参数，从而用户可以在系统启动或者模块装载时再指定参数值，这些参数对于驱动程序属于全局变量。\n模块参数会载入sysfs文件系统中，变为文件.\nmodule_param(name, type, perm);"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#导出符号表",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#导出符号表",
    "title": "Linux 内核设备和模块",
    "section": "导出符号表",
    "text": "导出符号表\n模块被载入后，就会被动态地连接(link)到内核，连接过程需要借助内核导出的符号表来访问内核函数。\n只有被显式导出的内核函数，才能被模块调用（类似动态链接库）。\n使用 EXPORT_SYMBOL()和EXPORT_SYMBOL_GPL() 可以在内核源码中显式导出内核函数：\nint get_pirate_beard_color(struct pirate *p)\n{\n  return p-&gt;beard.color;\n}\nEXPORT_SYMBOL(get_pirate_beard_color);\n导出的内核符号表被看作导出的内核接口，称为内核API"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#设备模型",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#设备模型",
    "title": "Linux 内核设备和模块",
    "section": "设备模型",
    "text": "设备模型\n设备模型提供了一个独立的机制专门来表示设备，并描述其在系统中的拓扑结构，从而使得系统具有以下优点:\n\n代码重复最小化\n提供诸如引用计数等统一机制\n可以列举系统中所有的设备，观察它们的状态，并且查看它们连接的总线。\n可以将系统中的全部设备结构以树的形式完整、有效地展现出来——包括所有的总线和内部连接。\n可以将设备和其对应的驱动联系起来，反之亦然。\n可以将设备按照类型加以归类，比如分类为输入设备，而无需理解物理设备的拓扑结构。\n可以沿设备树的叶子向其根的方向依次遍历，以保证能以正确顺序关闭各设备的电源。\n\n\nkobject\nkobject 类似于面向对象中的基类，设备类继承该类\n// include/linux/kobject.h\nstruct kobject {\n  const char    *name;\n  struct list_head  entry;\n  struct kobject    *parent;// 父对象指针，用于表达设备树中的层次关系\n  struct kset    *kset;\n  struct kobj_type  *ktype;\n  struct sysfs_dirent  *sd; // sysfs的dirent对象指针，指向本对象(本对象在sysfs中其实是一个文件)\n  struct kref    kref;// 引用计数\n  unsigned int state_initialized:1;\n  unsigned int state_in_sysfs:1;\n  unsigned int state_add_uevent_sent:1;\n  unsigned int state_remove_uevent_sent:1;\n  unsigned int uevent_suppress:1;\n};\nkobject的一个派生类是cdev ,表示字符设备:\nstruct cdev\n{\n  struct kobject kobj; // 嵌入kobject表示继承，必须放在结构体开头实现多态\n  // 后面为该类的特有成员\n  struct module *owner;\n  const struct file_operations *ops;\n  struct list_head list;\n  dev_t dev;\n  unsigned int count;\n};\n\n\nktype\nkobject 的成员 ktype 表示本 kobject 的类型，多个 kobject 可以关联同一个 ktype，描述一类 kobject 所具有的普遍特性。\n// include/linux/kobject.h\nstruct kobj_type {\n  void (*release)(struct kobject *kobj); // 引用计数归0时的析构函数，也就是同类kobject通用\n  const struct sysfs_ops *sysfs_ops; // sysfs 的操作方法\n  struct attribute **default_attrs; // 属性，是个数组\n  const struct kobj_ns_type_operations *(*child_ns_type)(struct kobject *kobj);\n  const void *(*namespace)(struct kobject *kobj);\n};\n\n\nkset\nkset 用于对诸多 kobject 及其派生类对象进行分组（分组和 ktype 无关，即使 ktype 相同的也能分到不同组中）。分组依据比如“全部的块设备”，kset 的存在让分组更灵活，而不受限于相同或是不同的 ktype。\nkset 的存在是为了将 kobject 分组映射为 sysfs 中的目录关系信息.\n// include/linux/kobject.h\nstruct kset {\n  struct list_head list; // 链表，连接该kset管理的所有组内kobj，指向kobj链表上的第一个节点\n  spinlock_t list_lock; // 保护链表的自旋锁\n  struct kobject kobj; // 作为组内的所有kobject的基类,这是kset的一大功能\n  const struct kset_uevent_ops *uevent_ops; // 用于处理集合中kobject对象的热插拔操作\n};\nkset 对象作为链表头连接一组 kobject（kobj 之间通过 kobject 内的 entry 成员连接）："
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#引用计数",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#引用计数",
    "title": "Linux 内核设备和模块",
    "section": "引用计数",
    "text": "引用计数\n类似于高级语言的gc机制，当引用数为０时回收对象.\nkref结构：\n// include/linux/kref.h\nstruct kref {\n  atomic_t refcount;\n};\n引用计数操作方法：\nstruct kobject *kobject_get(struct kobject *kobj);\nvoid kobject_put(struct kobject *kobj);"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#sysfs中添加和删除kobject",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#sysfs中添加和删除kobject",
    "title": "Linux 内核设备和模块",
    "section": "sysfs中添加和删除kobject",
    "text": "sysfs中添加和删除kobject\nkobject默认初始化后并不关联到sysfs,需要使用kobject_add() ．"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#向sysfs中添加文件attr",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#向sysfs中添加文件attr",
    "title": "Linux 内核设备和模块",
    "section": "向sysfs中添加文件(attr)",
    "text": "向sysfs中添加文件(attr)\nkobject对应sysfs中的目录，而kobject对象中的default_attr数组对应sysfs中的文件．\n该数组负责将内核数据映射成sysfs中的文件．"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#默认文件",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#默认文件",
    "title": "Linux 内核设备和模块",
    "section": "默认文件",
    "text": "默认文件\nkobject对象中的成员default_attrs 数组表示目录下的默认文件，sysfs_ops成员则描述了如何使用这些文件：\n// include/linux/sysfs.h\nstruct sysfs_ops {\n  // 读取文件,从kobj（表示目录）和attr（表示文件）中，读取数据到buf中\n  ssize_t  (*show)(struct kobject *kobj, struct attribute *attr,char *buf);\n  // 写入文件\n  ssize_t  (*store)(struct kobject *,struct attribute *,const char *, size_t);\n  const void *(*namespace)(struct kobject *, const struct attribute *);\n};"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#文件的创建与修改",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#文件的创建与修改",
    "title": "Linux 内核设备和模块",
    "section": "文件的创建与修改",
    "text": "文件的创建与修改\n一般而言，相同 ktype 的 kobject 的 default_attrs 都是相同的，也就是这些目录下的文件组织结构(文件名，权限)都相同。\n//　创建文件\nint sysfs_create_file(struct kobject *kobj, const struct attribute tattr);\n//  创建符号链接\nint sysfs_create_link(struct kobject *kobj, struct kobject *target, char *name);\n//  删除新文件\nvoid sysfs_remove_file(struct kobject *kobj, const struct attribute *attr);\n//  删除符号链接\nvoid sysfs_remove_link(struct kobject *kobj, char *name) ;"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#sysfs约定",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#sysfs约定",
    "title": "Linux 内核设备和模块",
    "section": "sysfs约定　",
    "text": "sysfs约定　\n\n一值一文件：sysfs 属性应该保证每个文件只导出一个值，该值应该是文本形式而且映射为简单 C 类型。避免文件内容过于复杂，这样使用 shell 或 C 语言读取写入该文件就会简单得多。\n清晰的层次组织数据\nsysfs 提供内核到用户空间的服务\nsysfs 已经取代 ioctl() 和 procfs，尽可能得使用 sysfs 操作内核变量"
  },
  {
    "objectID": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#内核事件层",
    "href": "posts/Linux内核设备与模块/Linux 内核设备和模块.html#内核事件层",
    "title": "Linux 内核设备和模块",
    "section": "内核事件层",
    "text": "内核事件层\n内核事件层实现了内核到用户的消息通知系统（通过 kobject 和 sysfs）\n事件是实现异步操作的必要组成部分，常见事件如硬盘满了，处理器过热了，分区挂载了。\n每个事件源都是一个 sysfs 路径，比如一个硬盘通知事件源为 /sys/block/hda。\n内核事件由内核空间传递到用户空间需要经过netlink（netlink 是一个用于传送网络信息的多点传送套接字）。使用示例：在用户空间实现一个系统后台服务用于监听套接字(socket)，处理任何读到的信息，并将事件传送到系统栈里，通过该方法也能实现将事件整合入 D-BUS。\n在内核代码中向用户空间发送信号使用函数kobject_uevent(), 最终事件就是包含 kobject 对应的 sysfs 路径和信号动作的字符串。"
  },
  {
    "objectID": "posts/软硬件协同迷思/软硬件协同迷思.html",
    "href": "posts/软硬件协同迷思/软硬件协同迷思.html",
    "title": "软硬件协同迷思",
    "section": "",
    "text": "最初的出发点是用自动调优在软件性能优化和硬件设计间建立直接联系，与传统自动调优不同的是，这要基于一些硬件设计参数去建模，并计算程序性能，而不是用真机或机器学习的黑盒模型，因为这样才能获得硬件设计参数的直接反馈，例如哪些参数组合是均衡的，哪些存在瓶颈且瓶颈在哪。\n由此得出以下几个判断：\n\n从改硬件设计、kernel优化、瓶颈分析再回到硬件设计，这个反馈链太长，互动效率往往不高；\n手动优化汇编是落后的生产力，工作量大扩展性差；\n算力比人力更有竞争力，机器自动搜索比人力搜索适用性更强；\n问题复杂度增加时，算力比人力更容易扩展；\n\n根据上述判断，结合目前可行的技术分析，可以在现有编译器的基础上，只加入新功能的简单支持，然后用上层语言最多是IR实现自动调优。\n遇到的问题：\n\n硬件功能在设计时就没仔细考虑软件的用法和使用场景。同时具备“硬件工程师+了解具体使用场景和流程”的人很少，这是架构师的能力范围。每个功能的软硬件对接都需要慢慢调试，没有几代产品的相互磨合，是很难做好的。需要有人能够既懂软件应用，懂一点编译器，也懂一点硬件架构，承担技术串联的角色，才能打破技术壁垒，更流畅地实现从底层硬件到上层软件的功能输送。\n编译器的后端优化自动化程度远远不够，依然费时费力。如果只是使用x86和CUDA的编译器，因为这两家的编译器比较成熟，所以优化效果比较好，但是如果要支持新的ISA或者硬件架构，就需要自己去重新实现优化。LLVM中仅有tablegen+支持后端自动化优化，很多部分都要重新磨合；MLIR中有Table Driven Declarative Rewrite Rule，但自动化程度也有限；TVM中自动调优多数在LLVM以上，硬件后端优化不是重点。所以后端优化问题也需要解决。\n硬件建模还是有很多看不清的工作量。对于一些简单的算子和算法，其运算过程哪些硬件参数有影响，能够大致有谱，但像Cache Hit Rate的估计，就有些玄妙。大部分时候有统计规律可循，但也有严重偏离规律的情况发生。这时候，软硬协同的价值也体现出来了，提前对接有助于暴露问题。对于硬件设计的规律，多数情况是软件迁就硬件，软件一要补硬件的坑，二要发挥硬件的能力。并且软件更新迭代成本更小，所以要用软件去补足硬件短板。\n\n\n\n\n软硬件设计不是竞技，但有时候能做的事情选择不做，也是有一定考量的。在软件实现中，CUDA一些函数的corner case中会用到local memory，即使GPR充裕也不转存GPR，因为用local memory，只要不进入到这个corner 分支，那就几乎没有开销，最多费一点指令cache。而如果用GPR，那即使不进入这个分支，也会影响总GPR数，从而影响Occupancy。也就是说只要使用了额外的GPR，不管这部分代码有没有运行，它都有开销，即使有时候是无害的。\nNV的硬件运行逻辑上也有很多限制，比如64bit或128bit访存指令的地址必须对齐，操作64bit和128bit的GPR也必须对齐。NV也有一些常见的指令不支持，也有些指令会重复。所以，很多功能的做或不做，还是有诸多考虑的。\nNV的一些调度逻辑，例如control codes，也从硬件转移到了软件，这应该是因为编译器具有更全局的视野，可以更好地做依赖分析和指令调度，同时也简化硬件设计，节省面积。\n还有一些功能被直接舍弃了，例如NV中没有算数异常处理的功能，比如除0，移除之类的，L1 Cache之间也没有Coherence。这很难用软件弥补，所以干脆软件和硬件都不支持了。\n\n\n\n一个应用，从算法开始，到软件实现，再到编译的中间表示，再到机器指令，都是信息一级一级传递的过程。协同优化也是信息交互的过程，例如最常见的矩阵乘法，在算子曾可以用标准实现，也可以用快速矩阵乘法实现，如果知道是卷积或者其他特殊矩阵，就可以有特定的加速算法。普通的矩阵乘算法，有相应的矩阵乘加速器或是tensorcore，也可以做相应的加速。如果是矩阵连乘或可融合的操作，在上层也容易实现相应的优化。\n但是信息传递也存在很多困难，不管是C还是LLVM的IR，都有一些硬件操作难以表述，最终变成内置函数。内置函数多了，上层表示就难以理解和优化，最后会堆积到硬件后端，这其中会损失一些可能的优化。\n最后到指令集的问题，什么样的指令集方便优化呢？显然，每个指令都一样慢的最好优化，只要没有冗余就算是优化好了，但这显然与设计追求不相符。我认为好的指令集应该具有表述能力强（一个功能有多种独立实现），独立性好（类似函数式逻辑，相互干扰少），资源瓶颈少（例如各种barrier，carr flag都有多个选择，不会导致相关操作序列化）等特点。从上层看，就是指令调度和算数优化的可能性比较多，自由度大。另外一点是对信息的具体化能力较强，比如不同的依赖关系可以用不同的scoreboard保证次序，减少干扰。"
  },
  {
    "objectID": "posts/软硬件协同迷思/软硬件协同迷思.html#软硬件的技术隔阂",
    "href": "posts/软硬件协同迷思/软硬件协同迷思.html#软硬件的技术隔阂",
    "title": "软硬件协同迷思",
    "section": "",
    "text": "最初的出发点是用自动调优在软件性能优化和硬件设计间建立直接联系，与传统自动调优不同的是，这要基于一些硬件设计参数去建模，并计算程序性能，而不是用真机或机器学习的黑盒模型，因为这样才能获得硬件设计参数的直接反馈，例如哪些参数组合是均衡的，哪些存在瓶颈且瓶颈在哪。\n由此得出以下几个判断：\n\n从改硬件设计、kernel优化、瓶颈分析再回到硬件设计，这个反馈链太长，互动效率往往不高；\n手动优化汇编是落后的生产力，工作量大扩展性差；\n算力比人力更有竞争力，机器自动搜索比人力搜索适用性更强；\n问题复杂度增加时，算力比人力更容易扩展；\n\n根据上述判断，结合目前可行的技术分析，可以在现有编译器的基础上，只加入新功能的简单支持，然后用上层语言最多是IR实现自动调优。\n遇到的问题：\n\n硬件功能在设计时就没仔细考虑软件的用法和使用场景。同时具备“硬件工程师+了解具体使用场景和流程”的人很少，这是架构师的能力范围。每个功能的软硬件对接都需要慢慢调试，没有几代产品的相互磨合，是很难做好的。需要有人能够既懂软件应用，懂一点编译器，也懂一点硬件架构，承担技术串联的角色，才能打破技术壁垒，更流畅地实现从底层硬件到上层软件的功能输送。\n编译器的后端优化自动化程度远远不够，依然费时费力。如果只是使用x86和CUDA的编译器，因为这两家的编译器比较成熟，所以优化效果比较好，但是如果要支持新的ISA或者硬件架构，就需要自己去重新实现优化。LLVM中仅有tablegen+支持后端自动化优化，很多部分都要重新磨合；MLIR中有Table Driven Declarative Rewrite Rule，但自动化程度也有限；TVM中自动调优多数在LLVM以上，硬件后端优化不是重点。所以后端优化问题也需要解决。\n硬件建模还是有很多看不清的工作量。对于一些简单的算子和算法，其运算过程哪些硬件参数有影响，能够大致有谱，但像Cache Hit Rate的估计，就有些玄妙。大部分时候有统计规律可循，但也有严重偏离规律的情况发生。这时候，软硬协同的价值也体现出来了，提前对接有助于暴露问题。对于硬件设计的规律，多数情况是软件迁就硬件，软件一要补硬件的坑，二要发挥硬件的能力。并且软件更新迭代成本更小，所以要用软件去补足硬件短板。"
  },
  {
    "objectID": "posts/软硬件协同迷思/软硬件协同迷思.html#软硬件的分工和协作是难点",
    "href": "posts/软硬件协同迷思/软硬件协同迷思.html#软硬件的分工和协作是难点",
    "title": "软硬件协同迷思",
    "section": "",
    "text": "软硬件设计不是竞技，但有时候能做的事情选择不做，也是有一定考量的。在软件实现中，CUDA一些函数的corner case中会用到local memory，即使GPR充裕也不转存GPR，因为用local memory，只要不进入到这个corner 分支，那就几乎没有开销，最多费一点指令cache。而如果用GPR，那即使不进入这个分支，也会影响总GPR数，从而影响Occupancy。也就是说只要使用了额外的GPR，不管这部分代码有没有运行，它都有开销，即使有时候是无害的。\nNV的硬件运行逻辑上也有很多限制，比如64bit或128bit访存指令的地址必须对齐，操作64bit和128bit的GPR也必须对齐。NV也有一些常见的指令不支持，也有些指令会重复。所以，很多功能的做或不做，还是有诸多考虑的。\nNV的一些调度逻辑，例如control codes，也从硬件转移到了软件，这应该是因为编译器具有更全局的视野，可以更好地做依赖分析和指令调度，同时也简化硬件设计，节省面积。\n还有一些功能被直接舍弃了，例如NV中没有算数异常处理的功能，比如除0，移除之类的，L1 Cache之间也没有Coherence。这很难用软件弥补，所以干脆软件和硬件都不支持了。"
  },
  {
    "objectID": "posts/软硬件协同迷思/软硬件协同迷思.html#软硬件的信息传递和协同优化密切相关",
    "href": "posts/软硬件协同迷思/软硬件协同迷思.html#软硬件的信息传递和协同优化密切相关",
    "title": "软硬件协同迷思",
    "section": "",
    "text": "一个应用，从算法开始，到软件实现，再到编译的中间表示，再到机器指令，都是信息一级一级传递的过程。协同优化也是信息交互的过程，例如最常见的矩阵乘法，在算子曾可以用标准实现，也可以用快速矩阵乘法实现，如果知道是卷积或者其他特殊矩阵，就可以有特定的加速算法。普通的矩阵乘算法，有相应的矩阵乘加速器或是tensorcore，也可以做相应的加速。如果是矩阵连乘或可融合的操作，在上层也容易实现相应的优化。\n但是信息传递也存在很多困难，不管是C还是LLVM的IR，都有一些硬件操作难以表述，最终变成内置函数。内置函数多了，上层表示就难以理解和优化，最后会堆积到硬件后端，这其中会损失一些可能的优化。\n最后到指令集的问题，什么样的指令集方便优化呢？显然，每个指令都一样慢的最好优化，只要没有冗余就算是优化好了，但这显然与设计追求不相符。我认为好的指令集应该具有表述能力强（一个功能有多种独立实现），独立性好（类似函数式逻辑，相互干扰少），资源瓶颈少（例如各种barrier，carr flag都有多个选择，不会导致相关操作序列化）等特点。从上层看，就是指令调度和算数优化的可能性比较多，自由度大。另外一点是对信息的具体化能力较强，比如不同的依赖关系可以用不同的scoreboard保证次序，减少干扰。"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "fywc",
    "section": "",
    "text": "About this blog hehehe"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "fywc",
    "section": "Education",
    "text": "Education\nInstitute of Computing Technology | Bei jing, CN Master in Computer Science | Sept 2022 - June 2025\nBeijing Jiaotong University | Bei jing, CN Bachelor in Computer Science | Sept 2018 - June 2022"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fywc’s Blog",
    "section": "",
    "text": "软硬件协同迷思\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGDB命令集合\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinux 内核设备和模块\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeadlock-Livelock-Starvation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n数据结构与算法\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nfywc\n\n\nOct 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHarlow Malloc\n\n\nFeb 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nCS6.175\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nfywc\n\n\nFeb 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nRookieCore\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nfywc\n\n\nFeb 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\nnews\n\n\n\n\n\n\n\nTristan O’Malley\n\n\nFeb 3, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/CS6.175/index.html",
    "href": "posts/CS6.175/index.html",
    "title": "CS6.175",
    "section": "",
    "text": "Lab4要求实现4种不同的FIFO，这些FIFO可以从不同程度上实现并发,也就是实现enqueue和dequeue方法。\n一般来说主要有三种FIFO，分别是Depth-1 Pipeline FIFO, Depth-1 Bypass FIFO, Depth-2 ConflictFree FIFO. 这三种FIFO所需的面积最小。\n与FIFO相比，FIFOF的优点是增加了notempty和notfull寄存器，可以很方便地判断空/满状态，缺点则是更多寄存器使得面积更大。\n\nConflict FIFO\n不可以同时enq和deq\nPipeline FIFO\n满时可以同时进行deq和enq\n {notEmpty, first, deq} &lt; {notFull, enq} &lt; clear\nBypass FIFO\n空时可以同时进行enq和deq\n {notFull, enq} &lt; {notEmpty, first, deq} &lt; clear\nConflict-Free FIFO 任何时候都可以同时进行 enq 和 deq\n\n    {notFull, notEmpty, deq, enq, first} &lt; clear"
  },
  {
    "objectID": "posts/CS6.175/index.html#四种fifo",
    "href": "posts/CS6.175/index.html#四种fifo",
    "title": "CS6.175",
    "section": "",
    "text": "Lab4要求实现4种不同的FIFO，这些FIFO可以从不同程度上实现并发,也就是实现enqueue和dequeue方法。\n一般来说主要有三种FIFO，分别是Depth-1 Pipeline FIFO, Depth-1 Bypass FIFO, Depth-2 ConflictFree FIFO. 这三种FIFO所需的面积最小。\n与FIFO相比，FIFOF的优点是增加了notempty和notfull寄存器，可以很方便地判断空/满状态，缺点则是更多寄存器使得面积更大。\n\nConflict FIFO\n不可以同时enq和deq\nPipeline FIFO\n满时可以同时进行deq和enq\n {notEmpty, first, deq} &lt; {notFull, enq} &lt; clear\nBypass FIFO\n空时可以同时进行enq和deq\n {notFull, enq} &lt; {notEmpty, first, deq} &lt; clear\nConflict-Free FIFO 任何时候都可以同时进行 enq 和 deq\n\n    {notFull, notEmpty, deq, enq, first} &lt; clear"
  },
  {
    "objectID": "posts/CS6.175/index.html#ehr寄存器",
    "href": "posts/CS6.175/index.html#ehr寄存器",
    "title": "CS6.175",
    "section": "EHR寄存器",
    "text": "EHR寄存器\nEHR寄存器是一种特殊的寄存器，可以同时进行寄存器的读取和写入操作，而不需要任何同步或者锁定机制，适用于流水线设计。缺点是EHR会导致关键路径过长，而且难以跟踪具体路径。\n\n\n\n\nr0\nw0\nr1\nw1\n\n\n\n\nr0\nCF\n&lt;\nCF\n&lt;\n\n\nw0\n&gt;\nC\n&lt;\n&lt;\n\n\nr1\nCF\n&gt;\nCF\n&lt;\n\n\nw1\n&gt;\n&gt;\n&gt;\nC\n\n\n\n其中，优先级依次是w1 &gt; r1 &gt; w0 &gt; r0"
  },
  {
    "objectID": "posts/CS6.175/index.html#单周期",
    "href": "posts/CS6.175/index.html#单周期",
    "title": "CS6.175",
    "section": "单周期",
    "text": "单周期"
  },
  {
    "objectID": "posts/CS6.175/index.html#双周期",
    "href": "posts/CS6.175/index.html#双周期",
    "title": "CS6.175",
    "section": "双周期",
    "text": "双周期\n\n\n\n\n\nflowchart LR\n  A[取指] --&gt; B[执行]"
  },
  {
    "objectID": "posts/CS6.175/index.html#四周期",
    "href": "posts/CS6.175/index.html#四周期",
    "title": "CS6.175",
    "section": "四周期",
    "text": "四周期\n\n\n\n\n\nflowchart LR\n  A[取指] --&gt; B[译码]\n  B --&gt; C[执行]\n  C --&gt; D[写回]"
  },
  {
    "objectID": "posts/CS6.175/index.html#二级流水线",
    "href": "posts/CS6.175/index.html#二级流水线",
    "title": "CS6.175",
    "section": "二级流水线",
    "text": "二级流水线\n\n\n\n\n\nflowchart LR\n  A[取指] --&gt; B[执行]"
  },
  {
    "objectID": "posts/CS6.175/index.html#六级流水线",
    "href": "posts/CS6.175/index.html#六级流水线",
    "title": "CS6.175",
    "section": "六级流水线",
    "text": "六级流水线\n\n\n\n\n\nflowchart LR\n  A[取指] --&gt; B[译码]\n  B --&gt; C[读寄存器]\n  C --&gt; D[执行]\n  D --&gt; E[访存]\n  E --&gt; F[写回]"
  },
  {
    "objectID": "posts/CS6.175/index.html#btb",
    "href": "posts/CS6.175/index.html#btb",
    "title": "CS6.175",
    "section": "BTB",
    "text": "BTB\n包括当前指令的地址current_pc和预测地址predicted_pc. ## BHT\n通常采用二位饱和计数器，包括当前指令的地址current_pc和计数器taken_prediction\nBHT可以和BTB合并在一起保存，格式如：\n\n\n\ncurrent_pc\npredicted_pc\ntaken_prediction"
  },
  {
    "objectID": "posts/CS6.175/index.html#ras",
    "href": "posts/CS6.175/index.html#ras",
    "title": "CS6.175",
    "section": "RAS",
    "text": "RAS\nRAS仅用于函数返回地址的预测。\n当程序执行到分支跳转指令时，RAS判断指令是否属于函数调用类型的分支跳转指令。若遇到rd = x1的JAL/JALR指令，则RAS将返回地址入栈; 若遇到rd = x0 && rs1 = x1的JALR指令，则从RAS出栈，作为函数返回地址使用。"
  },
  {
    "objectID": "posts/CS6.175/index.html#cache",
    "href": "posts/CS6.175/index.html#cache",
    "title": "CS6.175",
    "section": "Cache",
    "text": "Cache\n\nBlocking Cache\n阻塞式缓存在未命中时会向内存发出请求，等待内存响应后才能继续处理后续请求。\n这种方式会导致处理器停顿，降低性能。\n\n\n\n\n\nflowchart LR\n  A[Ready] --&gt; B[StartMiss]\n  B --&gt; C[SendFillReq]\n  C --&gt; D[WaitFillResp]\n  D --&gt; E[Resp]\n\n\n\n\n\n\n\nReady: 处理器可以继续执行下一条指令\nStartMiss：处理器发出未命中请求\nSendFillReq：处理器发送访存请求到内存\nWaitFillResp：处理器等待内存响应\nResp：处理器接收到内存响应\n\n\n\nNonBlocking Cache\n非阻塞式缓存能够在接收到未命中请求后，无须空等就能继续处理其他请求。\n非阻塞式缓存的实现方式是MSHR。MSHR是一个队列，用于存储未命中的请求。\n非阻塞式缓存的miss有三种：\n\nprimary miss：某个块的第一次miss\nsecondary miss：对某个已经在fetch的block中又一次miss。\nstructural-stall miss：由于MSHR数量不够导致的miss，会发生阻塞。\n\n\n\nMSI\n\n\n\nMSI\n\n\n\n\nMESI\n\n\n\nMESI\n\n\n\n\nMOSI\n\n\n\nMOSI\n\n\n\n\nMOESI\n\n\n\nMOESI"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html",
    "href": "posts/gdb集合/GDB命令集合.html",
    "title": "GDB命令集合",
    "section": "",
    "text": "Set\n\n启动\n运行\n设置/查看断点\n设置/查看观察点\n设置/查看捕捉点\n维护停止点\n维护条件停止点\n停止点设置运行命令\n断点菜单\n恢复程序运行和单步调试\n信号\n产生信号量\n线程\n查看栈信息\n查看源码\n搜索源码\n指定源文件路径\n源代码内存\n查看运行时数据\n查看内存\n自动显示\n设置显示选项\n环境变量\n查看寄存器\n修改程序的执行\n跳转执行\n强制函数返回\n强制调用函数\n\nReferenece"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#目录",
    "href": "posts/gdb集合/GDB命令集合.html#目录",
    "title": "GDB命令集合",
    "section": "",
    "text": "Set\n\n启动\n运行\n设置/查看断点\n设置/查看观察点\n设置/查看捕捉点\n维护停止点\n维护条件停止点\n停止点设置运行命令\n断点菜单\n恢复程序运行和单步调试\n信号\n产生信号量\n线程\n查看栈信息\n查看源码\n搜索源码\n指定源文件路径\n源代码内存\n查看运行时数据\n查看内存\n自动显示\n设置显示选项\n环境变量\n查看寄存器\n修改程序的执行\n跳转执行\n强制函数返回\n强制调用函数\n\nReferenece"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#启动",
    "href": "posts/gdb集合/GDB命令集合.html#启动",
    "title": "GDB命令集合",
    "section": "启动",
    "text": "启动\n$ gdb program           # program是你的可执行文件，一般在当前目录\n$ gdb program core      # gdb同时调试运行程序和core文件，core是程序非法执行产生的文件\n$ gdb program pid       # 如果你的程序是一个服务程序，那么你可以指定这个服务程序运行时的进程ID。gdb会自动attach上去，并调试他。program应该在PATH环境变量中搜索得到。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#运行",
    "href": "posts/gdb集合/GDB命令集合.html#运行",
    "title": "GDB命令集合",
    "section": "运行",
    "text": "运行\n(gdb) r/run             # 开始运行程序\n(gdb) c/continue        # 继续运行\n(gdb) n/next            # 下一行，不进入函数调用\n(gdb) s/step            # 下一行，进入函数调用\n(gdb) ni/si             # 吓一跳指令，ni和si区别同上\n(gdb) fini/finish       # 继续运行至函数退出/当前栈帧\n(gdb) u/util            # 继续运行至某一行，在循环中，u可以实现运行至循环刚刚退出，但这取决于循环的实现\n\n(gdb) set args          # 设置程序启动参数，如：set args 10 20 30\n(gdb) show args         # 查看程序启动参数\n(gdb) path &lt;dir&gt;        # 设置程序的运行路径\n(gdb) show paths        # 查看程序的运行路径\n(gdb) set env &lt;name=val&gt;# 设置环境变量，如：set env USER=chen\n(gdb) show env [name]   # 查看环境变量\n(gdb) cd &lt;dir&gt;          # 相当于shell的cd命令\n(gdb) pwd               # 显示当前所在目录\n\n(gdb) shell &lt;commond&gt;   # 执行shell命令"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#设置查看断点",
    "href": "posts/gdb集合/GDB命令集合.html#设置查看断点",
    "title": "GDB命令集合",
    "section": "设置/查看断点",
    "text": "设置/查看断点\n(gdb) b/break linenum/func      # 在第linenum行或function处停住\n(gdb) b/break +/-offset         # 在当前行号后/前offset行停住\n(gdb) b/break filename:linenum  # 在源文件filename的linenum行停住\n(gdb) b/break filename:func     # 在源文件的function入口停住\n(gdb) b/break *address          # 在内存地址address处停住\n(gdb) b/break                   # 没有参数，表示下一跳指令处停住\n(gdb) b/break if &lt;condition&gt;    # 条件成立是停住，如在循环中：break if i=100\n\n(gdb) info break [n]            # 查看断点， n表示断点号"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#设置查看观察点",
    "href": "posts/gdb集合/GDB命令集合.html#设置查看观察点",
    "title": "GDB命令集合",
    "section": "设置/查看观察点",
    "text": "设置/查看观察点\n# 观察点一搬来观察某个表达式或变量的值是否有变化了，有：程序停住\n(gdb) watch &lt;expr&gt;              # 观察值是否有变化\n(gdb) rwatch &lt;expr&gt;             # 当expr被读取时，停住\n(gdb) awatch &lt;expr&gt;             # 当expr被读取或写入时，停住\n\n(gdb) info watchpoints          # 查看所有观察点"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#设置查看捕捉点",
    "href": "posts/gdb集合/GDB命令集合.html#设置查看捕捉点",
    "title": "GDB命令集合",
    "section": "设置/查看捕捉点",
    "text": "设置/查看捕捉点\n# 你可设置捕捉点来补捉程序运行时的一些事件。如：载入共享库（动态链接库）或是C++的异常。\n(gdb) tcatch &lt;event&gt;            # 只设置一次捕捉点\n(gdb) catch &lt;event&gt;             # 当event发生时，停住程序，如下：\n# throw             一个c++抛出的异常（throw为关键字）\n# catch             一个C++捕捉到的异常（catch为关键字）\n# exec              调用系统调用exec时（只在HP-UX下有用）\n# fork              调用系统调用fork时（只在HP-UX下有用）\n# vfork             调用系统调用vfork时（只在HP-UX下有用）\n# load [file]       载入共享库（动态链接库）时（只在HP-UX下有用）\n# unload [libname]  卸载共享库（动态链接库）时（只在HP-UX下有用）\n#"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#维护停止点",
    "href": "posts/gdb集合/GDB命令集合.html#维护停止点",
    "title": "GDB命令集合",
    "section": "维护停止点",
    "text": "维护停止点\n# 上面说了三种如何设置停止点的方法。在gdb中如果你觉得已经定义好的停止点没有用，那么你可以delete、clear、disable、enable进行维护\n(gdb) clear                     # 清除所有已定义的停止点。如果程序运行，清除当前行之后的\n(gdb) clear &lt;fuction&gt;           # 清除所有设置在函数上的停止点\n(gdb) clear &lt;file:line&gt;         # 清除所有设置在指定行上的停止点\n(gdb) d/delete [n]/[m-n]        # 删除断点号，不设置则删除全部，也可以范围m-n\n\n# 比删除更好的一种方法是disable停止点，disable了的停止点，GDB不会删除，当你还需要时，enable即可，就好像回收站一样。\n(gdb) disable [n]/[m-n]         # disable指定断点号n，不指定则disable所有，也可以范围m-n\n\n(gdb) enable [n]/[m-n]          # enable断点n，也可以范围m-n\n(gdb) enable once [n]/[m-n]     # enable断点n一次，程序停止后自动disable，也可以范围m-n\n(gdb) enable delete [n]/[m-n]   # enable断点，程序结束自动删除，也可以范围m-n"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#维护条件停止点",
    "href": "posts/gdb集合/GDB命令集合.html#维护条件停止点",
    "title": "GDB命令集合",
    "section": "维护条件停止点",
    "text": "维护条件停止点\n# 前面说到设置breakpoint可以设置成一个条件，这里列出相关的维护命令\n(gdb) condition &lt;bunm&gt; &lt;expr&gt;   # 修改断掉号bnum的停止条件\n(gdb) condition &lt;bnum&gt;          # 清除断点号bnum的停止条件\n\n# ignore 可以指定程序运行时，忽略停止条件几次\n(gdb) ignore &lt;bnum&gt; &lt;count&gt;     # 忽略断点号hnum的停止条件count次"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#停止点设置运行命令",
    "href": "posts/gdb集合/GDB命令集合.html#停止点设置运行命令",
    "title": "GDB命令集合",
    "section": "停止点设置运行命令",
    "text": "停止点设置运行命令\n# 当程序停住时，我们可以通过command设置其自动执行的命令，这很利于自动化调试。\n(gdb) commands [bnum]\n&gt; ... commands list ...\n&gt; end                   # 这里为断点号bnum设置一个命令列表\n\n如：\n(gdb) break foo if x&gt;0\n(gdb) commands\n&gt; printf \"x is %dn\",x\n&gt; continue\n&gt; end\n# 断点设置在函数foo中，断点条件是x&gt;0，如果程序被断住后，也就是，一旦x的值在foo函数中大于0，GDB会自动打印出x的值，并继续运行程序。\n# 如果你要清除断点上的命令序列，那么只要简单的执行一下commands命令，并直接在打个end就行了。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#断点菜单",
    "href": "posts/gdb集合/GDB命令集合.html#断点菜单",
    "title": "GDB命令集合",
    "section": "断点菜单",
    "text": "断点菜单\n# 如果你使用c++，有可能下断点时遇到相同名字的函数，gdb会为你列出该函数菜单供你选择。\n如：\n(gdb) b String::after\n[0] cancel\n[1] all\n[2] file:String.cc; line number:867\n[3] file:String.cc; line number:860\n[4] file:String.cc; line number:875\n[5] file:String.cc; line number:853\n[6] file:String.cc; line number:846\n[7] file\n&gt; 2 4 6\nBreakpoint 1 at 0xb26c: file String.cc, line 867.\nBreakpoint 2 at 0xb344: file String.cc, line 875.\nBreakpoint 3 at 0xafcc: file String.cc, line 846."
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#恢复程序运行和单步调试",
    "href": "posts/gdb集合/GDB命令集合.html#恢复程序运行和单步调试",
    "title": "GDB命令集合",
    "section": "恢复程序运行和单步调试",
    "text": "恢复程序运行和单步调试\n# 当程序被停住了，你可以用c/continue恢复运行，或下一个断点到来。也可以使用step或next命令单步跟踪程序。\n(gdb) c/continue [ignore-count]     # 恢复程序运行，ignore-count忽略后面断点数\n\n# 单步跟踪，如果有函数调用，他会进入该函数。进入函数的前提是，此函数被编译有debug信息。很像VC等工具中的stepin。后面可以加count也可以不加，不加表示一条条地执行，加表示执行后面的count条指令，然后再停住。\n(gdb) step &lt;count&gt;\n\n# 打开step-mode模式，于是，在进行单步跟踪时，程序不会因为没有debug信息而不停住。这个参数有很利于查看机器码。\n(gdb) set step-mode on\n\n# 当你厌倦了在一个循环体内单步跟踪时，这个命令可以运行程序直到退出循环体。\n(gdb) u/until\n\n# 单步跟踪一条机器指令！一条程序代码有可能由数条机器指令完成，stepi和nexti可以单步执行机器指令。与之一样有相同功能的命令是“display/i $pc” ，当运行完这个命令后，单步跟踪会在打出程序代码的同时打出机器指令（也就是汇编代码）\n(gdb) si/stepi\n(gdb) ni/stepi"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#信号",
    "href": "posts/gdb集合/GDB命令集合.html#信号",
    "title": "GDB命令集合",
    "section": "信号",
    "text": "信号\n# 信号是一种软中断，是一种处理异步事件的方法。一般来说，操作系统都支持许多信号。尤其是UNIX，比较重要应用程序一般都会处理信号。UNIX定义了许多信号，比如SIGINT表示中断字符信号，也就是Ctrl+C的信号，SIGBUS表示硬件故障的信号；SIGCHLD表示子进程状态改变信号；SIGKILL表示终止程序运行的信号，等等。信号量编程是UNIX下非常重要的一种技术。\n# GDB有能力在你调试程序的时候处理任何一种信号，你可以告诉GDB需要处理哪一种信号。你可以要求GDB收到你所指定的信号时，马上停住正在运行的程序，以供你进行调试。你可以用GDB的handle命令来完成这一功能。\n(gdb) handle &lt;signal&gt; &lt;keywords...&gt;\n# 在GDB中定义一个信号处理。信号&lt;signal&gt;可以以SIG开头或不以SIG开头，可以用定义一个要处理信号的范围（如：SIGIO-SIGKILL，表示处理从SIGIO信号到SIGKILL的信号，其中包括SIGIO，SIGIOT，SIGKILL三个信号），也可以使用关键字all来标明要处理所有的信号。一旦被调试的程序接收到信号，运行程序马上会被GDB停住，以供调试。其&lt;keywords&gt;可以是以下几种关键字的一个或多个。\n  nostop            # 当被调试的程序收到信号时，GDB不会停住程序的运行，但会打出消息告诉你收到这种信号。\n  stop          # 当被调试的程序收到信号时，GDB会停住你的程序。\n  print         # 当被调试的程序收到信号时，GDB会显示出一条信息。\n  noprint           # 当被调试的程序收到信号时，GDB不会告诉你收到信号的信息。\n  pass/noignore # 当被调试的程序收到信号时，GDB不处理信号。这表示，GDB会把这个信号交给被调试程序会处理。\n  nopass/ignore # 当被调试的程序收到信号时，GDB不会让被调试程序来处理这个信号。\n\n# 查看有哪些信号在被GDB检测中。\n(gdb) info signals\n(gdb) info handle"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#产生信号量",
    "href": "posts/gdb集合/GDB命令集合.html#产生信号量",
    "title": "GDB命令集合",
    "section": "产生信号量",
    "text": "产生信号量\n# 使用singal命令，可以产生一个信号量给被调试的程序。如：中断信号Ctrl+C。这非常方便于程序的调试，可以在程序运行的任意位置设置断点，并在该断点用GDB产生一个信号量，这种精确地在某处产生信号非常有利程序的调试。语法是：\n(gdb) signal &lt;singal&gt;\n# UNIX的系统信号量通常从1到15。所以&lt;singal&gt;取值也在这个范围。\n# single命令和shell的kill命令不同，系统的kill命令发信号给被调试程序时，是由GDB截获的，而single命令所发出一信号则是直接发给被调试程序的。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#线程",
    "href": "posts/gdb集合/GDB命令集合.html#线程",
    "title": "GDB命令集合",
    "section": "线程",
    "text": "线程\n# 当你的程序时多线程的，你可以定义断点是否在所有线程或某个线程\n(gdb) info threads                          # 查看线程\n(gdb) break &lt;line&gt; thread &lt;threadno&gt;        # 指定源程序line行，线程threadno停住\n(gdb) break &lt;line&gt; thread &lt;threadno&gt; if...  # 指定源程序line行，线程threadno停住，跟上条件\n\n如：\n(gdb) break frik.c:13 thread 28 if bartab &gt; lim"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#查看栈信息",
    "href": "posts/gdb集合/GDB命令集合.html#查看栈信息",
    "title": "GDB命令集合",
    "section": "查看栈信息",
    "text": "查看栈信息\n# 当程序被停住了，你需要做的第一件事就是查看程序是在哪里停住的。当你的程序调用了一个函数，函数的地址，函数参数，函数内的局部变量都会被压入“栈”（Stack）中。你可以用GDB命令来查看当前的栈中的信息。\n(gdb) bt/backtrace          # 打印当前的啊还能输调用栈的所有信息\n(gdb) bt/backtrace &lt;n&gt;      # 当n为正数，打印栈顶n层。为负数，打印栈低n层\n\n# 如果你要查看某一层的信息，你需要在切换当前的栈，一般来说，程序停止时，最顶层的栈就是当前栈，如果你要查看栈下面层的详细信息，首先要做的是切换当前栈。\n(gdb) f/frame &lt;n&gt;           # n从0开始，是栈中的编号\n(gdb) up &lt;n&gt;                # 向栈的上面移动n层。如无n，向上移动一层\n(gdb) down &lt;n&gt;              # 向栈的下面移动n层。如无n，向下移动一层\n\n# 栈的层编号，当前的函数名，函数参数值，函数所在文件及行号，函数执行到的语句。\n(gdb) f/frame\n\n# 这个命令会打印出更为详细的当前栈层的信息，只不过，大多数都是运行时的内内地址。比如：函数地址，调用函数的地址，被调用函数的地址，目前的函数是由什么样的程序语言写成的、函数参数地址及值、局部变量的地址等等。\n(gdb) info f/frame\n\n(gdb) info args             # 打印当前函数的参数名及值\n(gdb) info locals           # 打印当前函数中所有局部变量及值\n(gdb) info catch            # 打印当前函数中的异常处理信息"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#查看源码",
    "href": "posts/gdb集合/GDB命令集合.html#查看源码",
    "title": "GDB命令集合",
    "section": "查看源码",
    "text": "查看源码\n# 在程序编译时一定要加上-g的参数，把源程序信息编译到执行文件中。不然就看不到源程序了。\n(gdb) l                         # 显示当前行前后的源码\n(gdb) l -                       # 显示当前行前的源码\n(gdb) l +                       # 显示当前行后的源码\n(gdb) l/list &lt;linuenum/func&gt;    # 查看第linenum行或者function所在行附近的10行\n(gdb) l/list                    # 查看上一次list命令列出的代码后面的10行\n(gdb) l/list m,n                # 查看从第m行到第n行的源码。m不填，则从当前行到n\n(gdb) l/list -/+offset          # 查看想对当前行偏移offset源码\n(gdb) l/list &lt;file:line&gt;        # 查看文件file的line行的源码\n(gdb) l/list &lt;func&gt;             # 查看函数名func源码\n(gdb) l/list &lt;file:func&gt;        # 查看文件file的函数func源码\n(gdb) l/list &lt;*address&gt;         # 查看运行时内存地址address的源码\n\n(gdb) set listsize              # 设置一次显示源码的行数\n(gdb) show listsize             # 查看listsize的值"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#搜索源码",
    "href": "posts/gdb集合/GDB命令集合.html#搜索源码",
    "title": "GDB命令集合",
    "section": "搜索源码",
    "text": "搜索源码\n(gdb) forward-search &lt;regexp&gt;   # 向前搜索，regexp是一个正则表达式\n(gdb) search &lt;regexp&gt;           # 向前搜索\n(gdb) reverse-search &lt;regexp&gt;   # 全局搜索"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#指定源文件路径",
    "href": "posts/gdb集合/GDB命令集合.html#指定源文件路径",
    "title": "GDB命令集合",
    "section": "指定源文件路径",
    "text": "指定源文件路径\n# 某些时候，用-g编译过后的执行程序中只是包括了源文件的名字，没有路径名。GDB提供了可以让你指定源文件的路径的命令，以便GDB进行搜索。\n(gdb) dir/directory &lt;dirname ... &gt;  # 加一个源文件路径到当前路径的前面。如果你要指定多个路径，UNIX下你可以使用“:”，Windows下你可以使用“;”。\n(gdb) dir/directory                 # 清除所有的自定义的源文件搜索路径信息。\n(gdb) show directories              # 显示定义了的源文件搜索路径。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#源代码内存",
    "href": "posts/gdb集合/GDB命令集合.html#源代码内存",
    "title": "GDB命令集合",
    "section": "源代码内存",
    "text": "源代码内存\n(gdb) info line                     # 查看源代码在内存中的地址，还可以:\n(gdb) info line &lt;num&gt;\n(gdb) info line &lt;file:num&gt;\n(gdb) info line &lt;func&gt;\n(gdb) info line &lt;file:func&gt;\n\n# 还有一个命令（disassemble）你可以查看源程序的当前执行时的机器码，这个命令会把目前内存中的指令dump出来。如下面的示例表示查看函数func的汇编代码。\n(gdb) disassemble func"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#查看运行时数据",
    "href": "posts/gdb集合/GDB命令集合.html#查看运行时数据",
    "title": "GDB命令集合",
    "section": "查看运行时数据",
    "text": "查看运行时数据\n# &lt;expr&gt;是表达式，是你所调试的程序的语言的表达式（GDB可以调试多种编程语言），&lt;f&gt;是输出的格式，比如，如果要把表达式按16进制的格式输出，那么就是/x。\n(gdb) p/print &lt;expr&gt;            # expr可以是const常量、变量、函数等内容\n(gdb) p/print /&lt;f&gt; &lt;expr&gt;\n\n# 在表达式中，有几种GDB所支持的操作符，它们可以用在任何一种语言中。\n@                   是一个和数组有关的操作符，在后面会有更详细的说明。\n::                  指定一个在文件或是一个函数中的变量。\n{&lt;type&gt;} &lt;addr&gt;     表示一个指向内存地址&lt;addr&gt;的类型为type的一个对象。\n# 需要注意的是，如果你的程序编译时开启了优化选项，那么在用GDB调试被优化过的程序时，可能会发生某些变量不能访问，或是取值错误码的情况。\n# 输出格式\n# 一般来说，GDB会根据变量的类型输出变量的值。但你也可以自定义GDB的输出的格式。例如，你想输出一个整数的十六进制，或是二进制来查看这个整型变量的中的位的情况。要做到这样，你可以使用GDB的数据显示格式：\n  x 按十六进制格式显示变量。\n  d 按十进制格式显示变量。\n  u 按十六进制格式显示无符号整型。\n  o 按八进制格式显示变量。\n  t 按二进制格式显示变量。\n  a 按十六进制格式显示变量。 \n  c 按字符格式显示变量。 \n  f 按浮点数格式显示变量。\n  \n如：\n(gdb) p i\n$21 = 101\n(gdb) p/a i\n$22 = 0x65"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#查看内存",
    "href": "posts/gdb集合/GDB命令集合.html#查看内存",
    "title": "GDB命令集合",
    "section": "查看内存",
    "text": "查看内存\n# 你可以使用examine命令（简写是x）来查看内存地址中的值。x命令的语法如下所示：\n(gdb) x/&lt;n/f/u&gt; &lt;addr&gt;          # n, f, u可选\n\nn       是一个正整数，表示显示内存的长度，也就是说从当前地址向后显示几个地址的内容。\nf       表示显示的格式，参见上面。如果地址所指的是字符串，那么格式可以是s，如果地十是指令地址，那么格式可以是i。\nu       表示从当前地址往后请求的字节数，如果不指定的话，GDB默认是4个bytes。u参数可以用下面的字符来代替，b表示单字节，h表示双字节，w表示四字节，g表示八字节。当我们指定了字节长度后，GDB会从指内存定的内存地址开始，读写指定字节，并把其当作一个值取出来。\n&lt;addr&gt;  表示一个内存地址。\n\n# n/f/u三个参数可以一起使用。例如：\n(gdb) x/3uh 0x54320             #表示，从内存地址0x54320读取内容，h表示以双字节为一个单位，3表示三个单位，u表示按十六进制显示。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#自动显示",
    "href": "posts/gdb集合/GDB命令集合.html#自动显示",
    "title": "GDB命令集合",
    "section": "自动显示",
    "text": "自动显示\n# 你可以设置一些自动显示的变量，当程序停住时，或是在你单步跟踪时，这些变量会自动显示。相关的GDB命令是display。\n(gdb) display &lt;expr&gt;\n(gdb) display/&lt;fmt&gt; &lt;expr&gt;\n(gdb) display/&lt;fmt&gt; &lt;addr&gt;\n# expr是一个表达式，fmt表示显示的格式，addr表示内存地址，当你用display设定好了一个或多个表达式后，只要你的程序被停下来，GDB会自动显示你所设置的这些表达式的值。\n\n# 格式i和s同样被display支持，一个非常有用的命令是：\n(gdb) display/i $pc\n# $pc是GDB的环境变量，表示着指令的地址，/i则表示输出格式为机器指令码，也就是汇编。于是当程序停下后，就会出现源代码和机器指令码相对应的情形，这是一个很有意思的功能。\n下面是一些和display相关的GDB命令：\n(gdb) undisplay &lt;dnums...&gt;\n(gdb) delete display &lt;dnums...&gt;\n# 删除自动显示，dnums意为所设置好了的自动显式的编号。如果要同时删除几个，编号可以用空格分隔，如果要删除一个\n# 范围内的编号，可以用减号表示（如：2-5）\n(gdb) disable display &lt;dnums...&gt;\n(gdb) enable display &lt;dnums...&gt;\n# disable和enalbe不删除自动显示的设置，而只是让其失效和恢复。\n(gdb) info display\n# 查看display设置的自动显示的信息。GDB会打出一张表格，向你报告当然调试中设置了多少个自动显示设置，其中包括，设置的编号，表达式，是否enable。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#设置显示选项",
    "href": "posts/gdb集合/GDB命令集合.html#设置显示选项",
    "title": "GDB命令集合",
    "section": "设置显示选项",
    "text": "设置显示选项\n# GDB中关于显示的选项比较多，这里我只例举大多数常用的选项。\n# 1、打开地址输出，当程序显示函数信息时，GDB会显出函数的参数地址。系统默认为打开的\n(gdb) set print address\n(gdb) set print address on \n(gdb) set print address off     # 关闭函数的参数地址显示\n(gdb) show print address        # 查看当前地址显示选项是否打开。\n\n# 2、打开数组显示，打开后当数组显示时，每个元素占一行，如果不打开的话，每个元素则以逗号分隔。这个选项默认是关闭的。\n(gdb) set print array\n(gdb) set print array on \n(gdb) set print array off\n(gdb) show print array\n(gdb) show print elements       # 查看print elements的选项信息。\n(gdb) set print elements &lt;number-of-elements&gt;\n# 这个选项主要是设置数组的，如果你的数组太大了，那么就可以指定一个&lt;number-of-elements&gt;来指定数据显示的最大长度，当到达这个长度时，GDB就不再往下显示了。如果设置为0，则表示不限制。\n\n# 3、如果打开了这个选项，那么当显示字符串时，遇到结束符则停止显示。这个选项默认为off\n(gdb) set print null-stop &lt;on/off&gt;  \n\n# 4、如果打开printf pretty这个选项，那么当GDB显示结构体时会比较漂亮。\n(gdb) set print pretty on \n(gdb) show print pretty         # 查看GDB是如何显示结构体的。\\\n\n# 5、设置字符显示，是否按“nnn”的格式显示，如果打开，则字符串或字符数据按nnn显示，如“65”。\n(gdb) set print sevenbit-strings &lt;on/off&gt;\n(gdb) show print sevenbit-strings   # 查看字符显示开关是否打开。\n\n# 6、设置显示结构体时，是否显式其内的联合体数据。\n(gdb) set print union &lt;on/off&gt;\n(gdb) show print union              # 查看联合体数据的显示方式\n如：\n$1 = {it = Tree, form = {tree = Acorn, bug = Cocoon}}   # 开\n$1 = {it = Tree, form = {...}}                          # 关\n\n# 7、在C++中，如果一个对象指针指向其派生类，如果打开这个选项，GDB会自动按照虚方法调用的规则显示输出，如果关闭这个选项的话，GDB就不管虚函数表了。这个选项默认是off。\n(gdb) set print object &lt;on/off&gt;\n(gdb) show print object             # 查看对象选项的设置。\n\n# 8、这个选项表示，当显示一个C++对象中的内容是，是否显示其中的静态数据成员。默认是on。\n(gdb) set print static-members &lt;on/off&gt;\n(gdb) show print static-members     # 查看静态数据成员选项设置。\n\n# 9、当此选项打开时，GDB将用比较规整的格式来显示虚函数表时。其默认是关闭的。\n(gdb) set print vtbl &lt;on/off&gt;\n(gdb) show print vtbl               # 查看虚函数显示格式的选项。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#环境变量",
    "href": "posts/gdb集合/GDB命令集合.html#环境变量",
    "title": "GDB命令集合",
    "section": "环境变量",
    "text": "环境变量\n# 你可以在GDB的调试环境中定义自己的变量，用来保存一些调试程序中的运行数据。要定义一个GDB的变量很简单只需。 使用GDB的set命令。GDB的环境变量和UNIX一样，也是以$起头。如：\n(gdb) set $foo = *object_ptr\n# 使用环境变量时，GDB会在你第一次使用时创建这个变量，而在以后的使用中，则直接对其賦值。环境变量没有类型，你可以给环境变量定义任一的类型。包括结构体和数组。\n(gdb) show convenience\n# 该命令查看当前所设置的所有的环境变量。这是一个比较强大的功能，环境变量和程序变量的交互使用，将使得程序调试更为灵活便捷。例如：\n(gdb) set $i = 0\n(gdb) print bar[$i++]-&gt;contents\n# 于是，当你就不必，print bar[0]-&gt;contents, print bar[1]-&gt;contents地输入命令了。输入这样的命令后，只用敲回车，重复执行上一条语句，环境变量会自动累加，从而完成逐个输出的功能。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#查看寄存器",
    "href": "posts/gdb集合/GDB命令集合.html#查看寄存器",
    "title": "GDB命令集合",
    "section": "查看寄存器",
    "text": "查看寄存器\n# 寄存器中放置了程序运行时的数据，比如程序当前运行的指令地址（ip），程序的当前堆栈地址（sp）等等。你同样可以使用print命令来访问寄存器的情况，只需要在寄存器名字前加一个$符号就可以了。如：p $eip。\n(gdb) info registers        # 查看寄存器状态(除浮点寄存器)\n(gdb) info all-registers    # 查看所有寄存器状态\n(gdb) info registers regname# 查看指定寄存器状态，如：info rbp"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#修改程序的执行",
    "href": "posts/gdb集合/GDB命令集合.html#修改程序的执行",
    "title": "GDB命令集合",
    "section": "修改程序的执行",
    "text": "修改程序的执行\n# 一旦使用GDB挂上被调试程序，当程序运行起来后，你可以根据自己的调试思路来动态地在GDB中更改当前被调试程序的运行线路或是其变量的值，这个强大的功能能够让你更好的调试你的程序，比如，你可以在程序的一次运行中走遍程序的所有分支。\n\n# 一、修改变量值\n# 修改被调试程序运行时的变量值，在GDB中很容易实现，使用GDB的print命令即可完成。如：\n(gdb) print x=4\n# x=4这个表达式是C/C++的语法，意为把变量x的值修改为4，如果你当前调试的语言是Pascal，那么你可以使用Pascal的语法：x:=4。\n# 在某些时候，很有可能你的变量和GDB中的参数冲突，如：\n(gdb) whatis width\ntype = double\n(gdb) p width\n$4 = 13\n(gdb) set width=47\nInvalid syntax in expression.\n# 因为，set width是GDB的命令，所以，出现了“Invalid syntax in expression”的设置错误，此时，你可以使用set\n# var命令来告诉GDB，width不是你GDB的参数，而是程序的变量名，如：\n(gdb) set var width=47\n# 另外，还可能有些情况，GDB并不报告这种错误，所以保险起见，在你改变程序变量取值时，最好都使用set var格式的GDB命令。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#跳转执行",
    "href": "posts/gdb集合/GDB命令集合.html#跳转执行",
    "title": "GDB命令集合",
    "section": "跳转执行",
    "text": "跳转执行\n# 一般来说，被调试程序会按照程序代码的运行顺序依次执行。GDB提供了乱序执行的功能，也就是说，GDB可以修改程序的执行顺序，可以让程序执行随意跳跃。这个功能可以由GDB的jump命令来完：\n(gdb) jump &lt;linespec&gt;\n# 指定下一条语句的运行点。&lt;linespce&gt;可以是文件的行号，可以是file:line格式，可以是+num这种偏移量格式。表式着下一条运行语句从哪里开始。\n(gdb) jump &lt;address&gt;\n# 这里的&lt;address&gt;是代码行的内存地址。注意，jump命令不会改变当前的程序栈中的内容，所以，当你从一个函数跳到另一个函数时，当函数运行完返回时进行弹栈操作时必然会发生错误，可能结果还是非常奇怪的，甚至于产生程序Core Dump。所以最好是同一个函数中进行跳转。\n# 熟悉汇编的人都知道，程序运行时，有一个寄存器用于保存当前代码所在的内存地址。所以，jump命令也就是改变了这个寄存器中的值。于是，你可以使用“set $pc”来更改跳转执行的地址。如：\n(gdb) set $pc = 0x485"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#强制函数返回",
    "href": "posts/gdb集合/GDB命令集合.html#强制函数返回",
    "title": "GDB命令集合",
    "section": "强制函数返回",
    "text": "强制函数返回\n# 如果你的调试断点在某个函数中，并还有语句没有执行完。你可以使用return命令强制函数忽略还没有执行的语句并返回。\n(gdb) return\n(gdb) return &lt;expression&gt;\n# 使用return命令取消当前函数的执行，并立即返回，如果指定了&lt;expression&gt;，那么该表达式的值会被认作函数的返回值。"
  },
  {
    "objectID": "posts/gdb集合/GDB命令集合.html#强制调用函数",
    "href": "posts/gdb集合/GDB命令集合.html#强制调用函数",
    "title": "GDB命令集合",
    "section": "强制调用函数",
    "text": "强制调用函数\n(gdb) call &lt;expr&gt;\n# 表达式中可以一是函数，以此达到强制调用函数的目的。并显示函数的返回值，如果函数返回值是void，那么就不显示。\n# 另一个相似的命令也可以完成这一功能——print，print后面可以跟表达式，所以也可以用他来调用函数，print和call的不同是，如果函数返回void，call则不显示，print则显示函数返回值，并把该值存入历史数据中。"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html",
    "href": "posts/数据结构与算法/数据结构与算法.html",
    "title": "数据结构与算法",
    "section": "",
    "text": "Memory\n\nPhysical Layer\nVirtual Layer\n\nLocation:\n\nArrangement\n\nAlgorithm\n\nFundamental operations\n\nFundamental Algorithms\n\nSorting algorithms\n\nSearching Algorithm\n\nAlgorithm Design Techniques\n\nData Structures\n\nContiguous Memory Data Structures\nDiscontiguous Memory Data Structures\nCombination of CM and DCM\nLinear Data Structures\n\nArray\nDynamicArray\nRing Buffer\nLinkedList\nFreeList\nDouble Linked List\nCircularLinkedList\nCircularDoubleLinkedList\nStack\n\nStack via DynamicArray\nStack via LinkedList\nStack via Deque\n\nQueue\n\nQueue via DoubleLinkedList\nQueue via RingBuffer\nQueue via Double Stack\n\nDeque\n\nDeque via DoubleLinkedList\nDeque via Array\n\nPriority Queue\n\nPriorityQueue via DynamicArray\nPriorityQueue via LinkedList\nPriorityQueue via Deque\nPriorityQueue via BinaryHeap\n\nAssociative Collections\n\nUnorderedMap or HashTable\nSortedMap\nUnordered\nOrderedSet via HashTable and LinkedList\nOrderedSet via Self Balancing Tree\n\nStandard Library Data Structures\n\nCPP"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#目录",
    "href": "posts/数据结构与算法/数据结构与算法.html#目录",
    "title": "数据结构与算法",
    "section": "",
    "text": "Memory\n\nPhysical Layer\nVirtual Layer\n\nLocation:\n\nArrangement\n\nAlgorithm\n\nFundamental operations\n\nFundamental Algorithms\n\nSorting algorithms\n\nSearching Algorithm\n\nAlgorithm Design Techniques\n\nData Structures\n\nContiguous Memory Data Structures\nDiscontiguous Memory Data Structures\nCombination of CM and DCM\nLinear Data Structures\n\nArray\nDynamicArray\nRing Buffer\nLinkedList\nFreeList\nDouble Linked List\nCircularLinkedList\nCircularDoubleLinkedList\nStack\n\nStack via DynamicArray\nStack via LinkedList\nStack via Deque\n\nQueue\n\nQueue via DoubleLinkedList\nQueue via RingBuffer\nQueue via Double Stack\n\nDeque\n\nDeque via DoubleLinkedList\nDeque via Array\n\nPriority Queue\n\nPriorityQueue via DynamicArray\nPriorityQueue via LinkedList\nPriorityQueue via Deque\nPriorityQueue via BinaryHeap\n\nAssociative Collections\n\nUnorderedMap or HashTable\nSortedMap\nUnordered\nOrderedSet via HashTable and LinkedList\nOrderedSet via Self Balancing Tree\n\nStandard Library Data Structures\n\nCPP"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#physical-layer",
    "href": "posts/数据结构与算法/数据结构与算法.html#physical-layer",
    "title": "数据结构与算法",
    "section": "Physical Layer",
    "text": "Physical Layer\nThe physical layer of a computer system is responsible for the actual storage and retrieval of data in electronic or magnetic form. Memory in the physical layer is organized hierarchically, with different types and levels of memory. Types of Memory in the Physical Layer:\n\nRegisters\nCache Memory\nMain Memory(Random Access Memory: RAM)\nSecondary Memories: (HDD, SSD)\n\nPhysical memory is invisible to programs in virtual memory systems and as a programmer you’re not required to reason about it."
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#virtual-layer",
    "href": "posts/数据结构与算法/数据结构与算法.html#virtual-layer",
    "title": "数据结构与算法",
    "section": "Virtual Layer",
    "text": "Virtual Layer\n\nLocation:\n\nStack : Fast allocation. Faster access.\n\nMoving just an integer pointer for allocates/de-allocates memory.\n\nHeap : Slow Allocation. Slower access\n\nSearch Heap\nSync heap for other threads\nAllocate memory"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#arrangement",
    "href": "posts/数据结构与算法/数据结构与算法.html#arrangement",
    "title": "数据结构与算法",
    "section": "Arrangement",
    "text": "Arrangement\n\nContiguous Bulk allocation in continuous memory block. (faster access).\nDiscontiguous Dynamic allocation in separated memory blocks.(slower access)."
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#fundamental-operations",
    "href": "posts/数据结构与算法/数据结构与算法.html#fundamental-operations",
    "title": "数据结构与算法",
    "section": "Fundamental operations",
    "text": "Fundamental operations\n\nread\n\naccessDataBySequence() (Either forward or backward)\ngetIndexingInformation(): getStartIndex(), getEndIndex(), getNextIndex(forIndex), getPreviousIndex(forIndex)\naccessDataAtRandomIndex(:): For Random access, time complexity should be of order O(1).\naccessDataAtFront()\naccessDataAtBack()\n\nwrite\n\ninsertDataAtRandomIndex(:)\ninsertDataAtFront()\ninsertDataAtBack()\nremoveDataAtRandomIndex(:)\nremoveDataAtFront()\nremoveDataAtBack()\nupdateDataAtRandomIndex(:)\nupdateDataAtFront()\nupdateDataAtBack()\n\n\nFor example, Linear search algorithm uses accessDataBySequence and compare each item with a specified value to find the answer while Binary search algorithm needs accessDataAtRandomIndex operation. \nA note on Random Access: In the context of data structures, random access refers to the ability to instantly access a specific location. With Array, for instance, if you select a random index, the Array data structure can immediately provide you with the address of that index. However, if you attempt to access a random index in a LinkedList, the data structure cannot instantaneously provide the address. Instead, it must iterate from the beginning (starting from head) until it reaches the desired index. Consequently, LinkedLists are considered to have a time complexity of O(n) (Upper bound) for random access operation. Most algorithms require O(1) random access, and languages such as Java have introduced a marker interface(with no methods) called RandomAccess. This interface serves as a reminder that certain algorithms rely on random access. To ensure that these algorithms perform efficiently with your data structure, it is necessary to make it compatible with random access. \n\nFundamental Algorithms\nFundamental operations form the building blocks upon which algorithms are constructed. Conversely, certain algorithms play fundamental rules for other algorithms. Take, for instance, the impact of input data order on the time efficiency of algorithms. Sorting the data beforehand can greatly simplify our lives, as it has a significant positive effect on the efficiency of numerous algorithms. Sorting can be accomplished through two methods. The first method involves utilizing a sorting algorithm to arrange an unsorted collection. The second method involves utilizing specific data structures, such as binary search trees, that facilitate the sorting of data through amortization.\n\nSorting algorithms\nAll sort algorithms need getIndexingInformation, accessDataAtRandomIndex(:) operations. Also items must be comparable.\n\nIn-place sorting algorithms: They need updateDataAtRandomIndex(:) operation.\n\nBubble sort\nSelection sor\nInsertion sort\nHeap sort\nQuick sort\n\nNot In-Place Sorting Algorithms:\n\nMerge sort\nRadix sort (non-comparison)\nBucket sort (non-comparison)\n\n\n\n\n\nSearching Algorithm\n\nLinear search: needs accessDataBySequence()\nBinary search: needs accessDataAtRandomIndex(:) with O(1)"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#algorithm-design-techniques",
    "href": "posts/数据结构与算法/数据结构与算法.html#algorithm-design-techniques",
    "title": "数据结构与算法",
    "section": "Algorithm Design Techniques",
    "text": "Algorithm Design Techniques\n\nDivide and conquer\nRecursion\nRandomized algorithms: Input MUST be RANDOM.\nDynamic programming\nGreedy algorithms"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#contiguous-memory-data-structures",
    "href": "posts/数据结构与算法/数据结构与算法.html#contiguous-memory-data-structures",
    "title": "数据结构与算法",
    "section": "Contiguous Memory Data Structures",
    "text": "Contiguous Memory Data Structures\n\nInit with fixed size. size stays fixed.\nAddress of each block can be calculated via: start + k * blocksize. Random access time complexity is O(1)\nBulk memory allocation\nSame size memory blocks (Same type)\nBase data Structure example: Array"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#discontiguous-memory-data-structures",
    "href": "posts/数据结构与算法/数据结构与算法.html#discontiguous-memory-data-structures",
    "title": "数据结构与算法",
    "section": "Discontiguous Memory Data Structures",
    "text": "Discontiguous Memory Data Structures\n\nThis arrangement is a special kind of Graph (We can represent graphs using it).\nEach block contains the address of next block.\nTime complexity for random access operation is O(n)\nDynamic memory allocation\nMemory block sizes can be different (Different types).\nBase data structure example: LinkedList"
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#combination-of-cm-and-dcm",
    "href": "posts/数据结构与算法/数据结构与算法.html#combination-of-cm-and-dcm",
    "title": "数据结构与算法",
    "section": "Combination of CM and DCM",
    "text": "Combination of CM and DCM\n\nA contiguous-memory array of pointers to contiguous-memory or discontiguous-memory collection of objects.\nTime complexity for random access operations is O(1) (via array of pointers) but accessing objects in non-continuous memory have a little overhead.\nBulk memory allocation for address (pointer) array, dynamic memory allocation for objects.\nObjects can have different memory sizes (different types).\nBase data structure example: An array of referenced objects in most programming languages."
  },
  {
    "objectID": "posts/数据结构与算法/数据结构与算法.html#linear-data-structures",
    "href": "posts/数据结构与算法/数据结构与算法.html#linear-data-structures",
    "title": "数据结构与算法",
    "section": "Linear Data Structures",
    "text": "Linear Data Structures\nBy employing one or a combination of the aforementioned concepts, basic data structures can be implemented, serving as the foundation for more intricate data structures. Additionally, the space and time complexities, as well as memory costs, can be readily analyzed by leveraging the complexities and costs associated with these fundamental concepts.\n\nArray\nIn Programming languages, Arrays are built-in types. Array of pointers (or array of reference types) acts like Combination of CM and DCM. For primitive types (or value types like Int, enum, struct in C#,Swift,…) if stored in stack, the behavior is like Contiguous Memory data structures. But if the primitives get boxed and be allocated in the heap, the behavior is like Combination of CM and DCM.\n\nBasic operations time complexity: Same as Contiguous Memory data structures\nGood:\n\naccessAtRandomIndex, insertAtBack, removeAtBack operations.\nBulk memory allocation (fast).\nContiguous memory. Fast access.\nIf used with primitive types (Value types), no dynamic memory allocation cost.\n\nNot good:\n\ninsertAtFront, insertAtMiddle, removeAtFront, removeAtMiddle Operations.\nFixed size.\n\nProgramming Languages implementations:\n\nCPP: Array size is compile-time constant.\n\n\n\n\n\nDynamicArray\nSimilar to array, but can grow at runtime. DynamicArray of pointers (or DynamicArray of reference types) acts like Combination of CM and DCM. For primitive types (or value types like Int, enum, struct in C#,Swift,…) the behavior is like Contiguous Memory data structures. Steps for resizing:\n\nallocate new array with new size\ncopy the old array values to the new array\ndelete the old array\n\n\nBasic operations time complexity: Same as Contiguous Memory data structures\nGood:\n\naccessAtRandomIndex, insertAtBack, removeAtBack operations.\nBulk memory allocation (fast).\nIf used with primitive types (Value types), no dynamic memory allocation cost.\n\nNot good:\n\ninsertAtFront, insertAtMiddle, removeAtFront, removeAtMiddle Operations.\nNew memory allocations and copy cost when capacity is full.\nHas unused memory allocation based on growth strategy. For example in Swift programming language, each time an array capacity is full, it double the capacity of the array.\n\nProgramming Languages implementations:\n\nCPP: Vector.\n\n\n\n\nRing Buffer\nA ring buffer is a specialized data structure implemented using an array. It is a static-sized buffer where read and write operations occur through two distinct pointers that iterate through the array in a circular manner.\n\n\nBasic operations time complexity: Same as Array with the following improvement:\n\ninsertAtFront is O(1)\nremoveAtFront is O(1)\n\nGood:\n\naccessAtRandomIndex, insert operation.\nBulk memory allocation (fast).\nIf used with primitive types (Value types), no dynamic memory allocation cost.\nAs it is fixed-size, we can map it to virtual memory layer memory page to make it super fast.\n\nNot good:\n\nFixed size.\nWrite operations may fail if the frequency of writes exceeds the frequency of reads.\n\nProgramming Languages implementations:\n\nCPP: Has no built-in implementation for LinkedList. Here is an implementation.\n\n\n\n\nLinkedList\n\n\nBasic operations time complexity: Same as Discontiguous Memory data structures with one improvement.\n\ninsertAtBack() becomes O(1) because we keep track of tail.\nremoveAtBack() stays O(n) because we have to iterate from head to index n-1 to remove n.\n\nGood:\n\ninsertAtFront, removeAtFront, insertAtBack operations.\n\nNot good:\n\naccessAtRandomIndex, removeAtBack, insertAtMiddle, removeAtMiddle Operations.\nDynamic memory allocation (slow).\n\nProgramming Languages implementations:\n\nCPP: forward_list.\n\n\n\n\n\nFreeList\nAs you have noticed, one of the Not Goods of a LinkedList data structure is dynamic memory allocation. It means, whenever you need a new node, you have to create a new one dynamically using new keyword. Dynamic memory allocation is a heavy task. One way of resolving this issue is to use FreeLists. FreeLists can be thought of as a reservoir for the LinkedList nodes. One approach is to initialize a FreeList with a sequence of nodes and whenever you need a Node for your LinkedList, you get one from the FreeList instance and when you remove a Node from the LinkedList, you will not free the memory, but return it to the FreeList reservoir to be used again later. Another approach is the following implementation for LinkedListNode with a private static freelist. In this implementation, the freelist is not initialized with an initial size but it grows as the new nodes are added.\nclass LinkListNode&lt;E&gt; {      // Singly linked list node with freelist support\n    // Extensions to support freelists\n    private static LinkListNode freelist = null;                  // Freelist for the class\n\n    private E value;       // Value for this node\n    private LinkListNode&lt;E&gt; next;    // Point to next node in list\n    // Constructors\n    LinkList(E it, LinkListNode&lt;E&gt; inn) { value = it; next = inn; }\n    LinkList(LinkListNode&lt;E&gt; inn) { value = null; next = inn; }\n\n    E element() { return value; }                        // Return the value\n    E setElement(E it) { return value = it; }            // Set element value\n    LinkListNode&lt;E&gt; next() { return next; }                     // Return next link\n    LinkListNode&lt;E&gt; setNext(LinkListNode&lt;E&gt; inn) { return next = inn; } // Set next link\n\n    // Return a new link, from freelist if possible\n    static &lt;E&gt; LinkListNode&lt;E&gt; get(E it, LinkListNode&lt;E&gt; inn) {\n      if (freelist == null) {\n        return new LinkListNode&lt;E&gt;(it, inn);                 // Get from \"new\"\n      }\n      LinkListNode&lt;E&gt; temp = freelist;                       // Get from freelist\n      freelist = freelist.next();\n      temp.setElement(it);\n      temp.setNext(inn);\n      return temp;\n    }\n\n    // Return a link node to the freelist\n    void release() {\n      value = null;   // Drop reference to the element\n      next = freelist;\n      freelist = this;\n    }\n  }\n\n\nDouble Linked List\n\n\nBasic operations time complexity: Same as Discontiguous Memory data structures with two improvements:\n\ninsertAtBack() becomes O(1).\nremoveAtBack() becomes O(1). Now we have access to n-1 from n and we can remove the pointer to n from n-1.\n\nGood:\n\ninsertAtFront, removeAtFront, insertAtBack, removeAtBack operations.\n\nNot good:\n\naccessAtRandomIndex, insertAtMiddle Operations.\nDynamic memory allocation (slow).\nHigh overhead of extra storage for the forward and back reference.\n\nProgramming Languages implementations:\n\nCPP: list is doubly linkedList.\n\n\n\n\n\nCircularLinkedList\n\n\nBasic operations time complexity: Same as LinkedList with some more capabilities.\n\nWe can traverse to a previous node\nWe can traverse in loop.\n\n\n\n\nCircularDoubleLinkedList\n\n\nBasic operations time complexity: Same as DoubleLinkedList with some more capabilities.\n\nWe can traverse to a previous node\nWe can traverse in loop in both direction.\n\n\n\n\nStack\nStack is a Last-In-First-Out(LIFO) data structure. Any data structure that is Good at insert/remove from one of the ends can be used as a container for Stack. Based on this, stacks can be implemented using DynamicArray (Good at add/remove from the back), LinkedList (Good at add/remove from front), DoubleLinkedList(Good at add/remove from both front and back) and Deque. Each implementation inherits Good and Not Good of the container data structure.\n\n\nStack via DynamicArray\n\nBasic operations time complexity: Same as DynamicArray:\nMethods:\n\npush(): insertAtBack on array container.\npop: removeAtBack on array container.\n\nGood:\n\npush() and pop() are O(1) operations.\nBulk memory allocation for pointers.\nIf used with primitive types (value types), no dynamic memory allocation cost.\n\nNot good:\n\nNew memory allocations and copy cost when internal array capacity is full.\nHas unused memory allocation based on growth strategy of the pointer array.\n\nProgramming Languages implementations:\n\nCPP: Stack. In CPP vector, deque and list(DoubleLinkedList) can be used as container for Stack.\n\n\n\n\n\nStack via LinkedList\n\nBasic operations time complexity: Same as LinkedList. We use Head of LinkedList to insert/remove.\nMethods:\n\npush(): insertAtFront on LinkedList container.\npop: removeAtFront on LinkedList container.\n\nGood:\n\npush() and pop() are O(1) operations.\n\nNot good:\n\naccessAtRandomIndex is O(n).\nDynamic memory allocation (slow).\n\n\n\n\n\nStack via Deque\nDeque data structure can be implemented using Deque via DoubleLinkedList or Deque via Array. The Deque can serve as a container for a Stack due to its behavior. C++ default container for Stack is deque.\n\n\n\nQueue\nQueue data structure is First-In-First-Out. Every data structure that is Good at addAtFront and removeAtBack or vice versa can be used as a container for Queue data structure. DoubleLinkedList(Good at add/remove at both ends) can be used as the containers for Queue data structure. Also RingBuffer can be used for fixed size queues. DynamicArray: is not a good container for queue data structure because of O(n) for insert operation. We can amortize this complexity using Queue via Double Stack (Stack via DynamicArray). Another approach is storing contents in multiple smaller arrays, allocating additional arrays at the beginning or end as needed. Indexing is implemented by keeping a dynamic array or a LinkedList containing pointers to each of the smaller arrays. In this case, the cost of inserting reduced from O(n) to the O(small_array.length). This approach is used for deque.\n\n\nQueue via DoubleLinkedList\n\nBasic operations time complexity: DoubleLinkedList\nMethods:\n\nenqueue(): insertAtFront on DoubleLinkedList container.\ndequeue(): removeAtBack on DoubleLinkedList container.\n\nGood:\n\nenqueue() and dequeue() are O(1) operations.\n\nNot good:\n\naccessAtRandomIndex operation.\nExtra memory for forward/backward pointers.\nDynamic memory allocation (slow).\n\nProgramming Languages implementations:\n\nCPP: queue in cpp can has deque or list (DoubleLinkedList) as the container. the default container is deque.\n\n\n\n\n\nQueue via RingBuffer\n\nBasic operations time complexity: RingBuffer\nMethods:\n\nenqueue(): insertAtRandomIndex on Array container.\ndequeue(): accessAtRandomIndex on Array container.\n\nGood:\n\nenqueue() and dequeue() are O(1) operations.\nIf used for primitive types (value types), No dynamic allocation.\n\nNot good:\n\nFixed size, enqueue() may fail.\n\n\n\n\n\nQueue via Double Stack\nIf we use DynamicArray as container for our queue, the dequeue() time complexity would be O(n) (Adding items to start of an array is an O(n) operation ). But we can amortize this complexity to O(1) using two stacks. LeftStack for enqueue() and the RightStack for dequeue(). Each time the LeftStack is empty, copy the RightStack contents to the LeftStack. This operation guarantees First-In-First-Out for the queue.\n\nBasic operations time complexity: Similar to Stack via DynamicArray.\nMethods:\n\nenqueue(): insertAtBack on left Array container (the enqueue stack).\ndequeue(): removeAtBack on right Array container (the dequeue stack).\n\nGood:\n\nenqueue() and dequeue() are O(1) operations.\nIf used for primitive types (value types), No dynamic allocation.\n\nNot good:\n\nNew memory allocations and copy cost when capacity is full.\nHas unused memory allocation based on growth strategy.\n\n\n\n\n\n\nDeque\nDeque (Double-Ended Queue) are a type of Queue that enqueue() and dequeue() can happen at both ends. Every data structure that is Good at insert/remove from both ends can be used as a container for Deque data structure. The only data structure that fullfil this requirement is DoubleLinkedList. Array is not a good data structure for implementing Deque data structure directly. However we can use some tricks to use Array as a container for Deque data structure. See Deque via Array.\n\n\nDeque via DoubleLinkedList\nImplementing a Deque via DoubleLinkedList is straightforward as this data structure has O(1) for insertAtFront/removeAtFront and insertAtBack/removeAtBack operations.\n\nMethods:\n\npushBack(): insertAtBack of the DoubleLinkedList container.\npushFront(): insertAtFront of the DoubleLinkedList container.\npopBack(): removeAtBack of the DoubleLinkedList container.\npopFront(): removeAtFront of the DoubleLinkedList container.\n\nGood:\n\nEasy implementation\n\nNot Good:\n\nRandom access operation.\nDynamic memory allocation (slow).\nHigh overhead of extra storage for the forward and back references.\n\n\n\n\n\nDeque via Array\nAs it was the case for Queue data structure, Array cannot be used as a container for Deque data structure directly because insertAtFront/removeAtFront operations are not O(1) for Arrays. We can use one of the following techniques to use Array as a container:\n\nUsing a special RingBuffer.\nUsing an Array and allocating deque contents from the center of the underlying array, and resizing the underlying array when either end is reached.\nStoring contents in multiple smaller arrays, allocating additional arrays at the beginning or end as needed. Indexing is implemented by keeping a dynamic array containing pointers to each of the smaller arrays. In this case, the cost of resizing the array in step 2 is eliminated but different small arrays are not allocated contiguously in memory.\n\n\nGood:\n\nRandom Access operation\n\nNot Good\n\nMore complex implementation\nNeed for array resize when filled\n\nProgramming Languages implementations:\n\nCPP: Deque uses approach 3 of above mentioned tricks to use Array as container for Deque. In this approach data is stored in smaller arrays and these arrays are linked using a doubleLinkedList or another array.\n\n\n\n\n\n\nPriority Queue\nPriorityQueue is the same as Queue with one difference. The dequeue operation is not for the first item that has been inserted. Instead the dequeue item is selected based on a priority criteria and the item may be at the front, the middle or the end of the collection. Any data structure that is Good at inserting at one of the ends can be used as a container for PriorityQueue. As finding the item to be dequeued includes a searching phase, for linear data structures as the container for PriorityQueue the time complexity of dequeue operation is O(n). In case of Heap data structure as the container, the time complexity reduces to O(log(n)) due to internal structure of the Heap.\n\n\nPriorityQueue via DynamicArray\n\nMethods:\n\nenqueue(): insertAtBack on Array container.\ndequeue(): iterate and then removeAtMiddle on Array container. Time complexity is O(n).\n\nGood:\n\nenqueue() is O(1) operation.\nIf used for primitive types (value types), No dynamic allocation.\n\nNot good:\n\ndequeue() operation is O(n).\nNew memory allocations and copy cost when capacity is full.\nHas unused memory allocation based on growth strategy.\n\nProgramming Languages implementations:\n\nCPP: priority_queue is using deque as a container by default. vector also can be used.\n\n\n\n\nPriorityQueue via LinkedList\n\nMethods:\n\nenqueue(): insertAtBack on Array container.\ndequeue(): iterate and then removeAtMiddle on Array container. Time complexity is O(n).\n\nGood:\n\nenqueue() is O(1) operation.\nIf used for primitive types (value types), No dynamic allocation.\n\nNot good:\n\ndequeue() operation is O(n).\nNew memory allocations and copy cost when capacity is full.\nHas unused memory allocation based on growth strategy.\n\nProgramming Languages implementations:\n\nCPP: priority_queue is using deque as a container by default. vector also can be used.\n\n\n\n\nPriorityQueue via Deque\nDeque data structure can be implemented using either Deque via DoubleLinkedList or Deque via Array and PriorityQueue can use it as a container.\n\n\nPriorityQueue via BinaryHeap\n\nMethods:\n\nenqueue(): insert on BinaryHeap container.\ndequeue(): delete on BinaryHeap container.\n\nGood:\n\ndequeue() is O(log(n)) operation.\n\nNot good:\n\nenqueue is O(log(n)) operation. In PriorityQueue via DynamicArray and PriorityQueue via LinkedList this operation is O(1).\n\n\n\n\n\nAssociative Collections\nAn associative collection is an abstract data type that stores a collection of (key, value) pairs, ensuring that each possible key appears at most once in the collection. However, there is no standardized naming convention for these types of data structures, leading to varying terminology across different programming languages, which can cause confusion. Some alternative names for associative collections include associative array, map, symbol table, or dictionary. See here.\n\nUnorderedMap or HashTable\nOther name is HashTable. The main idea behind a Hashtable is to use a hashing function to map keys to specific buckets or slots in an array. Each bucket can store one or more key-value pairs. Hash functions can occasionally generate the same index for different keys, resulting in a collision. To handle collisions efficiently, Hashtable data structures employ various strategies:\n\nEach bucket in the array is a LinkedList of key-value pairs.\nOpen addressing\nResizing the Array.\n\n‌For most data structures, a linear search is an O(n) or O(log(n)) operation. HashTable is a data structure with an amortized O(1) time complexity for searching. Length of arrays in a HashTable is a prime number.\n\n\nGood:\n\nO(1) for search operation.\n\nNot Good:\n\nCollection has no order. No Random access.\nIf LinkedList used for collision handling: Worst-case for search can be O(n) (All nodes collide). Average-case is not O(1).\n\nProgramming Languages implementations:\n\nCPP: unordered_map is an unordered collection created using HashTable. Another version is unordered_multimap that allows for repetitive keys. in the unordered_map version the keys are unique.\n\n\n\n\nSortedMap\nA collection of key-value pairs which is sorted by the key.\n\nGood:\n\nSearch is O(log(n))\nkeys are sorted.\n\nNot Good:\n\nRandom access is not O(1).\nSuitable for small number of data.\n\nProgramming Languages implementations:\n\nCPP: map uses Red-Black Tree for implementation. Another version is multimap which allows duplicate keys. In the map version, keys are unique.\n\n\n\n\nUnordered\nA collection of key-value pairs which is sorted by the key.\n\nGood:\n\nSearch is O(log(n))\nkeys are sorted.\n\nNot Good:\n\nRandom access is not O(1).\nSuitable for small number of data.\n\nProgramming Languages implementations:\n\nCPP: map uses Red-Black Tree for implementation. Another version is multimap which allows duplicate keys. In the map version, keys are unique.\n\n\n\n\nOrderedSet via HashTable and LinkedList\nIt is almost exactly like OrderedMap via HashTable and LinkedList with the distinction that the node has only a key and no value exists. In Java, it is implemented using HashTable and the values for the nodes are set to a fixed value.\n\nGood:\n\nOrder of the insertion is preserved. (Unlike SortedSet, the keys are not sorted.)\n\nNot Good:\n\nNo random access with O(1) because of LinkedList.\n\n\n\n\nOrderedSet via Self Balancing Tree\nIt is almost exactly like OrderedMap via HashTable and LinkedList with the distinction that the node has only a key and no value exists. In Java, it is implemented using HashTable and the values for the nodes are set to a fixed value.\n\nGood:\n\nOrder of the insertion is preserved. (Unlike SortedSet, the keys are not sorted.)\n\nNot Good:\n\nNo random access with O(1) because of LinkedList.\n\n\n\n\n\nStandard Library Data Structures\n\nCPP"
  },
  {
    "objectID": "posts/RookieCore/index.html",
    "href": "posts/RookieCore/index.html",
    "title": "RookieCore",
    "section": "",
    "text": "RookieCore 是一款简单的开源RISC-V处理器，采用三级流水:取指、译码、执行。 This is a post with executable code.\n\nif语句\nif语句每个分支都必须要使用 begin..end 包围起来，并且begin与if占同一行，end独占一行。\nif (a == 1'b1) begin\n    c &lt;= b;\nend\nelse begin\n    c &lt;= a;\nend\n\n\ncase语句\ncase语句每个分支中，如果只有一行语句则不包围，否则使用 begin..end包围起来，并且begin与分支语句占同一行，end独占一行。\ncase (a)\n    b: \n        c = d;\n    e: begin\n        c = f;\n        d = f;\n    end\n    default: begin\n        c = g;\n        d = g;\n    end\nendcase\n\n\nalways语句\nalways语句必须使用 begin..end 包围起来，并且begin与always语句占同一行，end独占一行。\nalways @ (posedge clk) begin\n    a &lt;= b;\nend"
  }
]